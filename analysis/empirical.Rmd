---
title: "Empirical use-resistance relationships over geographic scales"
author: "Scott Olesen"
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 4, fig.path = 'fig/',
  dev = c('png', 'pdf'), 
  echo = FALSE, warning = FALSE, message = FALSE,
  cache = TRUE, autodep = TRUE)

pdf.options(useDingbats = FALSE, useKerning = FALSE)

map = purrr::map
```

# Methods

## Data

### MarketScan

```{r maup_db}
state_data = read_tsv('../db/state_census.tsv')
```

```{r marketscan_data}
marketscan_res = read_tsv('~/grad/proj/medicare/analysis/ms2/data/abg_state.tsv') %>%
  rename(drug=drug_group) %>%
  mutate(bugdrug = case_when(
    .$bug == 'E. coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'S. pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'S. pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  filter(!is.na(bugdrug)) %>%
  mutate(n_resistant = as.integer(round(f_ns * n_isolates))) %>%
  select(bugdrug, drug, state, n_resistant, n_isolates)

marketscan_use = read_tsv('~/grad/proj/medicare/analysis/ms2/ineq_marketscan.tsv') %>%
  rename(drug = drug_group) %>%
  filter(drug %in% c('quinolone', 'beta_lactam', 'macrolide')) %>%
  mutate(use = total_use * 1000)

marketscan = marketscan_use %>%
  inner_join(marketscan_res, by = c('drug', 'state')) %>%
  rename(unit = state) %>%
  left_join(select(state_data, unit, population), by = 'unit') %>%
  select(unit, bugdrug, use, n_resistant, n_isolates, population)
```

### ECDC

```{r ecdc}
ecdc = read_tsv('../data/ecdc/data.tsv') %>%
  mutate(
    bug = case_when(
      .$bug == 'Escherichia coli' ~ 'E. coli',
      .$bug == 'Streptococcus pneumoniae' ~ 'S. pneumoniae',
      TRUE ~ 'other'),
    pct_res = 100 * f_ns,
    dataset = 'ECDC') %>%
  select(dataset, bug, drug,
         unit = country, use = did, n_resistant = n_ns,
         n_isolates, pct_res)
```

### NHSN/IMS

```{r nhsn_ims}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  mutate(dataset = 'NHSN/IMS', bug = 'E. coli', drug = 'quinolone',
         pct_res = 100 * n_resistant / n_isolates,
         use = us_europe_convert(drug, rx_1k_year)) %>%
  select(dataset, bug, drug, unit = state, use, pct_res, n_isolates)
```

# Results

## MarketScan

```{r marketscan_maup_setup}
# group n items into k groups, with at least n_min items in each group
sample_nmin = function(n, k, n_min = 2) {
  stopifnot(n_min * k <= n)
  sample(c(rep(1:k, each = n_min), sample(1:k, n - (n_min * k), replace = TRUE)))
}

renumber = function(x) match(x, unique(x))

# given distances between things, create groups
random_zones = function(distances, k) {
  stopifnot(nrow(distances) == ncol(distances))
  stopifnot(nrow(distances) >= k)
  
  centers = sample(1:nrow(distances), k)
  zones = distances[, centers] %>%
    apply(1, function(x) centers[which.min(x)])
  
  renumber(zones)
}

# wrapper around random zones, to ensure group size
random_zones_nmin = function(distances, k, n_min = 2, max_tries = 1e2) {
  try = 1
  while (try < max_tries) {
    z = random_zones(distances, k)
    if (min(table(z)) >= n_min) return(z)
    try = try + 1
  }
  
  NULL
}

deg2rad = function(deg) deg * pi / 180

haversine = function(long1, lat1, long2, lat2, R = 6371) {
  long1 = deg2rad(long1)
  lat1 = deg2rad(lat1)
  long2 = deg2rad(long2)
  lat2 = deg2rad(lat2)
  R * acos(pmin(1.0, sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(long2 - long1)))
}

unit_distances = function(unit_data) {
  stopifnot(all(c('unit', 'long', 'lat') %in% names(unit_data)))
  if (any(duplicated(unit_data$unit))) stop('duplicated units')

  units = unit_data$unit
  n_units = length(units)
  
  unit_data %>%
    crossing(., .) %>%
    arrange(unit, unit1) %>%
    mutate(dist = haversine(long, lat, long1, lat1)) %$%
    matrix(dist, ncol = n_units, nrow = n_units) %>%
    set_rownames(units) %>%
    set_colnames(units)
}
```

```{r maup_helper_functions}
aggregate = function(df, group) {
  mutate(df, group = group) %>%
    group_by(group) %>%
    summarize(use = weighted.mean(use, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           pct_res = n_resistant / n_isolates * 100)
}

group_models = function(df, group) {
  df %>%
    mutate(pct_res = n_resistant / n_isolates * 100) %>%
    split(group) %>%
    map(~ lm(pct_res ~ use, data = .))
}

try_load = function(fn, expr, force_run = FALSE) {
  if (!force_run && file.exists(fn)) {
    read_rds(fn)
  } else {
    value = expr
    write_rds(value, fn)
  }
}
```

```{r marketscan_maup_compute}
# create a hierarchical list: marketscan_maup_data$`Ec/q`$data
marketscan_maup_data = marketscan %>%
  nest(-bugdrug) %>%
  mutate(
    state_id = map(data, ~ match(.$unit, state.name)),
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

maup_group = function(maup_data, k, group_type) {
  switch(group_type,
         'sample' = sample_nmin(maup_data$n_units, k),
         'zone' = random_zones_nmin(maup_data$unit_distances, k),
         'region' = renumber(state.region[maup_data$state_id]),
         'division' = renumber(state.division[maup_data$state_id]),
         'state' = maup_data$state_id,
         'europe_region' = renumber(europe_units$region_name[maup_data[[.y]]$stat_id])
  )
}

n_iterations = 100

marketscan_canonical = crossing(
  bugdrug = marketscan$bugdrug,
  group_type = c('region', 'division', 'state')
)

europe_units = read_tsv('../db/europe_units.tsv') %>%
  select(unit = country, long = longitude, lat = latitude, population, unit_id, region_name)

add_canonical_data = function(df, maup_data) {
  df %>%
    mutate(group = map2(group_type, bugdrug,
                        ~ switch(.x,
                                 'region' = renumber(state.region[maup_data[[.y]]$state_id]),
                                 'division' = renumber(state.division[maup_data[[.y]]$state_id]),
                                 'state' = maup_data[[.y]]$state_id,
                                 'europe_region' = renumber(europe_units$region_name[maup_data[[.y]]$state_id])
                                 )),
           k = map_int(group, ~ length(unique(.))))
}

maup_sim = function(bugdrug, k, n_iterations, canonical_rows, maup_data, fn, force_run = FALSE) {
  try_load(fn, {
    crossing(
      bugdrug = bugdrug,
      k = k,
      group_type = c('sample', 'zone'),
      iteration = 1:n_iterations
    ) %>%
      mutate(group = pmap(list(bugdrug, k, group_type), ~ maup_group(maup_data[[..1]], ..2, ..3))) %>%
      bind_rows(add_canonical_data(canonical_rows, maup_data)) %>%
      mutate(
        group_data = map2(bugdrug, group, ~ aggregate(maup_data[[.x]]$data, .y)),
        group_type = if_else(group_type %in% c('state', 'region', 'division', 'europe_region'), 'canonical', group_type),
        super_model = map(group_data, ~ lm(pct_res ~ use, data = .)),
        super_slope = map_dbl(super_model, ~ coef(.)['use']),
        sub_models = map2(bugdrug, group, ~ group_models(maup_data[[.x]]$data, .y)),
        sub_slopes = map(sub_models, function(ms) map_dbl(ms, ~ coef(.)['use'])),
        median_sub_slope = map_dbl(sub_slopes, ~ median(., na.rm = TRUE)),
        slope_ratio = super_slope / median_sub_slope,
        # weighted linear models
        w_super_model = map(group_data, ~ lm(pct_res ~ use, weights = n_isolates, data = .)),
        w_super_slope = map_dbl(w_super_model, ~ coef(.)['use'])
      )
  }, force_run = force_run)
}

marketscan_maup = maup_sim(
  bugdrug = marketscan$bugdrug,
  k = c(4, 9),
  n_iterations = 100,
  canonical_rows = marketscan_canonical,
  maup_data = marketscan_maup_data,
  fn = 'results/marketscan_maup.rds',
  force_run = FALSE
)
```

### Canonical groupings

```{r marketscan_canonical}
marketscan_canonical_data = marketscan_maup %>%
  filter(group_type == 'canonical') %>%
  mutate(level = case_when(
    .$k == 4 ~ 'region',
    .$k == 9 ~ 'division',
    TRUE ~ 'state'
  )) %>%
  select(bugdrug, level, group_data) %>%
  unnest()
  
marketscan_canonical_data %>%
  ggplot(aes(use, pct_res, color = level)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_smooth(aes(fill = level), method = 'lm', alpha = 0.1) +
  geom_point()

marketscan_canonical_data %>%
  nest(-bugdrug, -level) %>%
  mutate(
    model = map(data, ~ lm(pct_res ~ use, data = .)),
    slope = map_dbl(model, ~ coef(.)['use']),
    slope_cil = map_dbl(model, ~ confint(.)['use', 1]),
    slope_ciu = map_dbl(model, ~ confint(.)['use', 2])
  ) %>%
  select(bugdrug, level, starts_with('slope')) %>%
  kable(caption = 'Slopes')
```

### MAUP

```{r marketscan_maup_table}
marketscan_state_slopes = marketscan_canonical_data %>%
  filter(level == 'state') %>%
  nest(-bugdrug) %>%
  mutate(model = map(data, ~ lm(pct_res ~ use, data = .)),
         state_slope = map_dbl(model, ~ coef(.)['use'])) %>%
  select(bugdrug, state_slope)

marketscan_maup %>%
  filter(group_type != 'canonical' | k %in% c(4, 9)) %>%
  select(bugdrug, k, group_type, super_slope) %>%
  nest(super_slope) %>%
  mutate(data = map(data, ~ unlist(., use.names = FALSE)),
         median_super = map_dbl(data, median),
         iqr_super = map_dbl(data, IQR)) %>%
  left_join(marketscan_state_slopes, by = 'bugdrug') %>%
  mutate(wilcox_p = map2_dbl(data, state_slope, ~ wilcox.test(.x - .y, alternative = 'greater')$p.value),
    fdr = p.adjust(wilcox_p, 'BH') < 0.05) %>%
  mutate(wilcox_p = if_else(group_type == 'canonical', NA_real_, wilcox_p),
         log10p = log10(wilcox_p),
         fdr = if_else(group_type == 'canonical', NA, fdr)) %>%
  select(bugdrug, k, group_type, state_slope, median_super, iqr_super, wilcox_p, log10p, fdr) %>%
  mutate_if(is.numeric, ~ round(., 3)) %>%
  arrange(bugdrug, group_type, k) %>%
  kable(caption = 'Comparing state and MAUP slopes')
```

Histogram of slopes over the random aggregates (zonal and sample) for each bug/drug and $k$. Dotted blue line shows the slope over the raw units (states).

```{r marketscan_maup_plot}
marketscan_maup %>%
  filter(group_type != 'canonical') %>%
  select(bugdrug, k, group_type, super_slope) %>%
  ggplot(aes(super_slope, fill = group_type)) +
  facet_grid(k ~ bugdrug, scales = 'free') +
  geom_vline(
    data = crossing(marketscan_state_slopes, k = c(4, 9)),
    aes(xintercept = state_slope),
    color = 'blue', linetype = 2
  ) +
  geom_histogram(position = 'dodge') +
  xlab('slope over random aggregate')
```

## IMS/NHSN CAUTIs

```{r nhsn}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  rename(state_abbreviation = state) %>%
  filter(state_abbreviation %in% state.abb) %>%
  mutate(state_id = match(state_abbreviation, state.abb),
         unit = state.name[state_id],
         bugdrug = 'Ec/q',
         use = us_europe_convert('quinolone', rx_1k_year)) %>%
  arrange(unit) %>%
  left_join(select(state_data, unit, population), by = 'unit') %>%
  select(unit, bugdrug, use, n_resistant, n_isolates, population)

nhsn_maup_data = nhsn %>%
  nest(-bugdrug) %>%
  mutate(
    state_id = map(data, ~ match(.$unit, state.name)),
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

nhsn_canonical = crossing(
  bugdrug = 'Ec/q',
  group_type = c('region', 'division', 'state')
)

nhsn_maup = maup_sim(
  bugdrug = 'Ec/q',
  k = c(4, 9),
  n_iterations = 100,
  canonical_rows = nhsn_canonical,
  maup_data = nhsn_maup_data,
  fn = 'results/nhsn_maup.rds',
  force_run = FALSE
)
```

### Canonical groupings

```{r nhsn_canonical}
nhsn_maup %>%
  filter(group_type == 'canonical') %>%
  mutate(level = case_when(
    .$k == 4 ~ 'region',
    .$k == 9 ~ 'division',
    TRUE ~ 'state'
  )) %>%
  select(bugdrug, level, group_data) %>%
  unnest() %>%
  ggplot(aes(use, pct_res, color = level)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_smooth(aes(fill = level), method = 'lm', alpha = 0.1) +
  geom_point()

nhsn_maup %>%
  filter(group_type == 'canonical') %>%
  mutate(level = case_when(
    .$k == 4 ~ 'region',
    .$k == 9 ~ 'division',
    TRUE ~ 'state'
  )) %>%
  mutate(model = map(group_data, ~ lm(pct_res ~ use, data = .)),
         slope = map_dbl(model, ~ coef(.)['use']),
         lci = map_dbl(model, ~ confint(.)['use', 1]),
         uci = map_dbl(model, ~ confint(.)['use', 2])) %>%
  select(bugdrug, level, slope, lci, uci)
```

### MAUP

**swo** refactor this in the same style as marketscan. also combine it with Europe at the same time?

```{r nhsn_maup_plot}
nhsn_maup %>%
  ggplot(aes(factor(k), super_slope, color = group_type)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_boxplot()

nhsn_maup %>%
  select(bugdrug, k, group_type, slope_ratio) %>%
  filter(is.finite(slope_ratio)) %>%
  ggplot(aes(factor(k), slope_ratio, color = group_type)) +
  geom_hline(yintercept = 1) +
  geom_boxplot() +
  ylim(-10, 10)

nhsn_maup %>%
  filter(group_type != 'canonical') %>%
  mutate(y = slope_ratio - 1) %>%
  nest(-bugdrug, -group_type, -k) %>%
  mutate(greater_p = map_dbl(data, ~ wilcox.test(.$y, alternative = 'greater')$p.value)) %>%
  select(-data) %>%
  kable()
```

```{r nhsn_numbers}
nhsn_maup %>%
  select(k, group_type, super_slope, median_sub_slope, slope_ratio) %>%
  gather('metric', 'value', super_slope, median_sub_slope, slope_ratio) %>%
  nest(value) %>%
  mutate(values = map(data, ~ .$value),
         median_ = map_dbl(values, median),
         variance = map_dbl(values, var),
         median_ci = map(values, ~ bootstrap_ci(., median)),
         median_lci = map_dbl(median_ci, ~ .[1]),
         median_uci = map_dbl(median_ci, ~ .[2]),
         variance_ci = map(values, ~ bootstrap_ci(., var)),
         variance_lci = map_dbl(variance_ci, ~ .[1]),
         variance_uci = map_dbl(variance_ci, ~ .[2])
  ) %>%
  filter(!(group_type == 'canonical' & metric %in% c('median_sub_slope', 'slope_ratio'))) %>%
  select(metric, group_type, k, median_, median_lci, median_uci, variance, variance_lci, variance_uci) %>%
  mutate_if(is.numeric, ~ round(., 2)) %>%
  arrange(metric, group_type, k) %>%
  kable()
```

### Example regions

```{r hex}
hex_map = read_tsv('~/grad/db/us_hex.tsv') %>%
  filter(!is.na(state)) %>%
  rename(unit = state)

hex_labels = hex_map %>%
  filter(order %in% c(0, 3)) %>%
  group_by(unit) %>%
  summarize_at(c('x', 'y'), mean) %>%
  mutate(abb = state.abb[match(unit, state.name)]) %>%
  crossing(k = c(4, 9), group_type = c('canonical', 'sample', 'zone'))

hex_borders = hex_map %>%
  crossing(k = c(4, 9), group_type = c('canonical', 'sample', 'zone'))

nhsn_maup %>%
  filter(group_type == 'canonical' | iteration == 1, k %in% c(4, 9)) %>%
  mutate(unit = map(group, ~ nhsn_maup_data$`Ec/q`$unit_data$unit)) %>%
  select(k, group_type, group, unit) %>%
  unnest() %>%
  right_join(hex_borders, by = c('unit', 'k', 'group_type')) %>%
  ggplot(aes(x, y, group = unit)) +
  facet_grid(group_type ~ k) +
  geom_polygon(aes(fill = factor(group)), color = 'black', show.legend = FALSE) +
  geom_text(data = hex_labels, aes(label = abb)) +
  coord_fixed() +
  theme_void()
```

## Europe

```{r europe_data}
europe = read_tsv('../data/ecdc/data.tsv') %>%
  mutate(bugdrug = case_when(
    .$bug == 'Escherichia coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  rename(unit = country) %>%
  left_join(select(europe_units, unit, population), by = 'unit') %>%
  select(unit, bugdrug, use, n_resistant = n_ns, n_isolates, population)

europe_names = unique(europe$unit)

europe_maup_data = europe %>%
  nest(-bugdrug) %>%
  mutate(
    state_id = map(data, ~ match(.$unit, europe_names)),
    unit_data = map(data, ~ filter(europe_units, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

# swo: come up with a better name than "state"
europe_canonical = crossing(
  bugdrug = europe$bugdrug,
  group_type = c('state', 'europe_region')
)

europe_maup = maup_sim(
  bugdrug = unique(europe$bugdrug),
  k = c(4),
  n_iterations = 100,
  canonical_rows = europe_canonical,
  maup_data = europe_maup_data,
  fn = 'results/europe_maup.rds',
  force_run = FALSE
)
```

### Canonical

```{r europe_canonical}
europe_maup %>%
  filter(group_type == 'canonical') %>%
  mutate(level = case_when(
    .$k == 4 ~ 'region',
    .$k == 9 ~ 'division',
    TRUE ~ 'state'
  )) %>%
  select(bugdrug, level, group_data) %>%
  unnest() %>%
  ggplot(aes(use, pct_res, color = level)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_smooth(aes(fill = level), method = 'lm', alpha = 0.1) +
  geom_point()
```

### MAUP

```{r europe_maup_plot}
europe_maup %>%
  ggplot(aes(factor(k), super_slope, color = group_type)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_boxplot()

europe_maup %>%
  select(bugdrug, k, group_type, slope_ratio) %>%
  filter(is.finite(slope_ratio)) %>%
  ggplot(aes(factor(k), slope_ratio, color = group_type)) +
  facet_wrap(~ bugdrug) +
  geom_hline(yintercept = 1) +
  geom_boxplot()

europe_maup %>%
  filter(group_type != 'canonical') %>%
  mutate(y = slope_ratio - 1) %>%
  nest(-bugdrug, -group_type, -k) %>%
  mutate(greater_p = map_dbl(data, ~ wilcox.test(.$y, alternative = 'greater')$p.value)) %>%
  select(-data) %>%
  kable()
```

```{r europe_numbers}
europe_maup %>%
  select(bugdrug, k, group_type, super_slope, median_sub_slope, slope_ratio) %>%
  gather('metric', 'value', super_slope, median_sub_slope, slope_ratio) %>%
  nest(value) %>%
  mutate(values = map(data, ~ .$value),
         median_ = map_dbl(values, median),
         variance = map_dbl(values, var),
         median_ci = map(values, ~ bootstrap_ci(., median)),
         median_lci = map_dbl(median_ci, ~ .[1]),
         median_uci = map_dbl(median_ci, ~ .[2]),
         variance_ci = map(values, ~ bootstrap_ci(., var)),
         variance_lci = map_dbl(variance_ci, ~ .[1]),
         variance_uci = map_dbl(variance_ci, ~ .[2])
  ) %>%
  filter(!(group_type == 'canonical' & metric %in% c('median_sub_slope', 'slope_ratio'))) %>%
  select(metric, bugdrug, group_type, k, median_, median_lci, median_uci, variance, variance_lci, variance_uci) %>%
  mutate_if(is.numeric, ~ round(., 2)) %>%
  arrange(metric, bugdrug, group_type, k) %>%
  kable()
```

## Canonical grouping analysis

### Table of results

### Significance test

**swo** clean up

There are some observed resistance values $y_i$ and uses $x_i$ in each state $i$. A linear fit $y_i \sim x_i$ gives the slope $m_1$. A linear fit on the aggregated data gives $m_2$. The null hypothesis is that $m_1 = m_2$, so the test statistic is $m_1 - m_2$. Is the observed value for that statistic consistent with the null hypothesis?

Define $m = \tfrac{1}{2}(m_1 + m_2)$ as an *ad hoc* guess for that underlying parameter, which defines the errors $\varepsilon_i = y_i - m x_i$. The sample population is defined by the distribution of the $\varepsilon_i$. To sample from the population, in each iteration, draw a bootstrap sample $\varepsilon^\star$ from the $\varepsilon$ to compute $y_i^\star = m x_i + \varepsilon_i^\star$. A regression $y_i^\star \sim x_i$ produces a slope $m_1^\star$, which is not necessarily equal to $m$. The regression on the aggregate data produces $m_2^\star$, and thus the sampled test statistic $m_1^\star - m_2^\star$.

```{r}
state_groups = select(state_data, unit, region, division)

adhoc = function(df) {
  df %>%
    left_join(state_groups, by = 'unit') %>%
    mutate(pct_res = 100 * n_resistant / n_isolates)
}

aggregate2 = function(df, group) {
  group_ = enquo(group)
  group_by(df, !!group_) %>%
    summarize(use = weighted.mean(use, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           pct_res = n_resistant / n_isolates * 100)
}

data_frame(bugdrug = names(marketscan_maup_data)) %>%
  mutate(state_d = map(bugdrug, ~ adhoc(marketscan_maup_data[[.]]$data)),
         state_slope = map_dbl(state_d, ~ coef(lm(pct_res ~ use, data = .))['use']),
         division_data = map(state_d, ~ aggregate2(., division)),
         division_slope = map_dbl(division_data, ~ coef(lm(pct_res ~ use, data = .))['use']),
         region_data = map(state_d, ~ aggregate2(., region)),
         region_slope = map_dbl(region_data, ~ coef(lm(pct_res ~ use, data = .))['use'])
         ) %>%
  identity()

bs_p = function(df1, group, n_iterations = 100) {
  group_ = enquo(group)
  
  df2 = df1 %>% aggregate2(!!group_)
  slope_f = function(df) coef(lm(pct_res ~ use, data = df))['use']
  
  m1 = slope_f(df1)
  m2 = slope_f(df2)
  m = mean(c(m1, m2))
  
  eps = df1$pct_res - m * df1$use
  
  f = function() {
    eps_bs = sample(eps, replace = TRUE)
    y_bs = m * df1$use + eps_bs
    
    m1_bs = coef(lm(y_bs ~ df1$use))[2]
    m2_bs = df1 %>%
      mutate(y_bs = y_bs) %>%
      group_by(!!group_) %>%
      summarize(use = weighted.mean(use, w = population),
                pct_res = weighted.mean(y_bs, w = n_isolates)) %>%
      lm(pct_res ~ use, data = .) %>%
      { coef(.)['use'] }
    
    m1_bs - m2_bs
  }
  
  diffs_bs = replicate(n_iterations, f())
  
  (sum(abs(m1 - m2) < abs(diffs_bs)) + 1) / (n_iterations + 1)
}

data_frame(bugdrug = names(marketscan_maup_data)) %>%
  mutate(state_d = map(bugdrug, ~ adhoc(marketscan_maup_data[[.]]$data)),
         region_p = map_dbl(state_d, ~ bs_p(., region)),
         division_p = map_dbl(state_d, ~ bs_p(., division))) %>%
  select(-state_d) %>%
  kable(caption = 'MarketScan empirical p for different slopes')

data_frame(state_d = list(adhoc(nhsn_maup_data$`Ec/q`$data))) %>%
  mutate(region_p = map_dbl(state_d, ~ bs_p(., region)),
         division_p = map_dbl(state_d, ~ bs_p(., division))) %>%
  select(-state_d) %>%
  kable(caption = 'NHSN')
```

## Distance analysis

If local tranmission "washes out" the use/resistance relationship, then we expect that pairs of states that are closer to one another will have a greater difference in resistance for the same difference in use. That is:
$$
\Delta \rho \sim \Delta \tau + \Delta \tau \times d
$$
We expect that $\beta_{\tau d} > 1$, meaning that greater distances $d$ give you a bonus in $\Delta \rho$ for that same $\Delta \tau$:
$$
\Delta \rho_i = \beta_\tau \Delta \tau + \beta_{\tau d} \Delta \tau \times d = \beta_\tau \left(1 + \frac{\beta_{\tau d}}{\beta_\tau} d \right) \Delta \tau.
$$
Or, more simply:
$$
\Delta \rho_i = A (1 + R \times d) \Delta \tau_i + C + \varepsilon_i
$$

**swo** the linear thing can easily be replaced by predicted the log odds ratio of resistance rather than delta rho. You get similar results.

```{r distance}
# fit the list of pairwise Delta rho, Delta tau, and distances
distance_nls = function(df) {
  # odds = function(p) p / (1 - p)
  # 
  # dff = df %>%
  #   mutate(o1 = odds(pct_res1 / 100),
  #          o2 = odds(pct_res2 / 100),
  #          lor = log(o2 / o1))
  
  # fit the lm for guessing values
  lm_model = lm(dr ~ du + du:dist, data = df)
  #lm_model = lm(lor ~ du + du:dist, data = dff)
  
  # fit the model
  nls_model = nls(
    dr ~ A * (1 + R * dist) * du + C,
    start = with(as.list(coef(lm_model)), list(A = du, R = `du:dist` / du, C = `(Intercept)`)),
    data = df
    #lor ~ A * (1 + R * dist) * du + C,
    # data = dff
  )
  
  nls_model
}

# turn the bugdrug bundle into a pairwise list of dr, du, and distances
distance_fit_data = function(bd) {
  # prepare the data set
  d = bd$data %>%
    mutate(f_res = n_resistant / n_isolates,
           pct_res = 100 * f_res,
           i = 1:n()) %>%
    select(unit, i, use, pct_res)
  
  # get all combinations of units
  units = unique(d$unit)
  x = crossing(unit1 = units, unit2 = units) %>%
    filter(unit1 < unit2) %>%
    left_join(d, by = c('unit1' = 'unit')) %>%
    left_join(d, by = c('unit2' = 'unit'), suffix = c('1', '2')) %>%
    mutate(dist = map2_dbl(i1, i2, ~ bd$unit_distances[.x, .y]),
           dr = pct_res2 - pct_res1,
           du = use2 - use1)
  
  x
}

distance_fit = function(dataset, lst) {
  data_frame(
    dataset = dataset,
    bugdrug = names(lst),
    data = map(lst, distance_fit_data),
    nls_model = map(data, distance_nls),
    ratio = map_dbl(nls_model, ~ coef(.)['R']),
    ratio_lci = map_dbl(nls_model, ~ confint.default(.)['R', 1]),
    ratio_uci = map_dbl(nls_model, ~ confint.default(.)['R', 2]),
    p_value = map_dbl(nls_model, ~ coef(summary(.))['R', 'Pr(>|t|)']),
    sig = p_value < 0.05,
    bh_sig = p.adjust(p_value, 'BH') < 0.05
  )
}

distance_fit_results = bind_rows(
  distance_fit('marketscan', marketscan_maup_data),
  distance_fit('nhsn', nhsn_maup_data),
  distance_fit('europe', europe_maup_data)
)

distance_fit_results %>%
  select(-data, -nls_model) %>%
  mutate_at(vars(starts_with('ratio')), ~ . * 1e3) %>%
  mutate_if(is.numeric, ~ round(., 3)) %>%
  arrange(bugdrug) %>%
  kable(caption = 'Observed results, and stat tests. Ratio in u/r per 1,000 km')
```

**swo** do this a little more cleanly

```{r distance_perm_perm}
distance_fit_data_f_perm = function(bd) {
  # prepare the data set,
  # permuting the indices
  d = bd$data %>%
    mutate(pct_res = 100 * n_resistant / n_isolates,
           i = sample(1:n())) %>%
    select(unit, i, use, pct_res)
  
  # get all combinations of units
  units = unique(d$unit)
  x = crossing(unit1 = units, unit2 = units) %>%
    filter(unit1 < unit2) %>%
    left_join(d, by = c('unit1' = 'unit')) %>%
    left_join(d, by = c('unit2' = 'unit'), suffix = c('1', '2')) %>%
    mutate(dist = map2_dbl(i1, i2, ~ bd$unit_distances[.x, .y]),
           dr = pct_res2 - pct_res1,
           du = use2 - use1)
  
  x
}

distance_fit_perm_p = function(bd, n_iter) {
  df1 = distance_fit_data(bd)
  
  obs_model = distance_nls(df1)
  obs_ratio = coef(obs_model)['R']
  
  obs_model2 = lm(dr ~ du + du:dist, data = df1)
  obs_ratio2 = with(as.list(coef(obs_model2)), `du:dist` / du)
  stopifnot(abs(obs_ratio - obs_ratio2) < 1e-6)
  
  perm_ratio = function() {
    perm_df = distance_fit_data_f_perm(bd)
    
    perm_model = lm(dr ~ du + du:dist, data = perm_df)
    with(as.list(coef(perm_model)), `du:dist` / du)
  }

  perm_ratios = replicate(n_iter, perm_ratio())

  r = sum(abs(obs_ratio) < abs(perm_ratios))
  p = (r + 1) / (n_iter + 1)
  
  p
}

distance_fit_perm = function(dataset, lst, n_iter) {
  data_frame(
    dataset = dataset,
    bugdrug = names(lst),
    p_value = map_dbl(lst, ~ distance_fit_perm_p(., n_iter))
  )
}

n_iter = 1e3
distance_fit_results_perm = bind_rows(
  distance_fit_perm('marketscan', marketscan_maup_data, n_iter),
  distance_fit_perm('nhsn', nhsn_maup_data, n_iter),
  distance_fit_perm('europe', europe_maup_data, n_iter)
)

distance_fit_results_perm %>%
  select(dataset, bugdrug, p_value) %>%
  mutate(sig = p_value < 0.05,
         adj_sig = p.adjust(p_value, 'BH') < 0.05) %>%
  kable(caption = 'Permutation p')
```

All the point estimates are positive, and some $p$-values are below $0.05$, but none pass an FDR $Q < 0.05$. Interestingly, the point estimates are fairly similar, in the range of $10^{-3}$ or below.

These results suggest that $\beta_{\tau d}/\beta_\tau$ is of order $10^{-3}$, measured in slope units (percentage points per DID) per kilometer. The distance between the US coasts is about 4,000 kilometers, so a large distance $d$ between states is on the order of 1,000 kilometers, and a large effect would be $\beta_{\tau d} d \approx 1$ percentage points per DID.

Strong slopes are 5-10, so getting a huge geographic range gives you an order of 10% bonus. Could be 50%, but it's not 10-fold.
