---
title: "Empirical use-resistance relationships over geographic scales"
author: "Scott Olesen"
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  fig.width=7, fig.height=4, fig.path='fig/',
  dev=c('png', 'pdf'),
  echo=FALSE, warning=FALSE, message=FALSE,
  cache=TRUE, autodep=TRUE)
pdf.options(useDingbats=FALSE, useKerning=FALSE)

state_map = map_data('state')
map = purrr::map
```

# To do

- If we take $n_1$ points from $N(0, \sigma^2_1)$ and $n_2$ from $N(0, \sigma^2_2)$, how do we evaluate if $\sigma^2_1 = \sigma^2_2$? Brown-Forsythe test
- Cite that guy for European centers?
- Include refs re: azithromycin

# Take-aways

## Simulation

- Moving to too small a length scale will really hurt the observed relationship
- Bigger length scales should give you worse power (because of decreased $n$) but no change in consistency.

## Empirical
- When you have more ways to choose how to aggregate the data, you can get many different results.
    - It's not obvious if there's one "correct" choice for how to aggregate.
    - It's not easy to look by eye and say, "this aggregation scheme will lead to a big/small use/res."
    - The canonical groupings are not obviously in the middle of the pack.
- Metrics were stable across many values of $k$.
    - Or, conversely, you could focus on how much they changed.
    - But I think it's pretty remarkable that you see similar relationships, on average, no matter how you aggregate.
- There's no general trend in higher vs. lower slopes depending on the size of the aggregates.
    - For Marketscan, bigger aggregates tend to have stronger median relationships (albeit with more variance).
    - For Europe, really big aggregates perform worse, suggesting that there are some cross-region differences in the use/resistance relationship.
- It's anecdotal, but for Marketscan, no clear data that the slope drops off when going from state to HRR.

## Synthesized

- Azithromycin trials suggest that you can go to really small length scales (sub-kebele).
- UK stuff suggests that you can go from CCG to practice level and still not have a problem.
- Our data suggests that going to larger scales isn't problematic, and that going to smaller scales is mostly limited by data collection.
- So, in conclusion, it seems like you should go as low as you can, and not worry too much.

# Methods

## US/Europe conversions

Most of the US studies and data are measured in prescriptions (or claims) per 1,000 people per year (PIY); the European studies are usually in DID (DDD per 1,000 people per year). Converting between the two requires asserting how many DDD are in one prescription.

I got these numbers by (1) looking in MarketScan and computing the average days' supply for claims for each drug and (2) comparing the CDDEP's within-US numbers (in PIY) with their across-country values for the US (in DID). They seem to disagree somewhat on the $\beta$-lactams. Something to be looked into a little more.

```{r piy_did}
us_europe_crosswalk = data_frame(
  drug = c('beta_lactam', 'quinolone', 'macrolide'),
  ddd_per_rx = c(10, 10, 7)
)

kable(us_europe_crosswalk)

# PIY = Prescriptions per 1,000 Inhabitants per Year
us_europe_convert = function(drug_, piy) {
  us_europe_crosswalk %$%
    { piy / 365 * ddd_per_rx[match(drug_, drug)] }
}
```

## Data

#### Medicare & ResistanceOpen

This is a nice chance to ask if going to a smaller scale gives you different regression coefficients. I compare the slopes of the use/resistance relationship when using HRRs and states.

```{r medicare_ro}
ro_bugdrugs = data_frame(
  bug = c('S. pneumoniae', 'S. pneumoniae', 'E. coli'),
  drug_group = c('beta_lactam', 'macrolide', 'quinolone')
)

ro_state = read_tsv('../data/ms-medicare-ro/abg_state.tsv')
ro_hrr = read_tsv('../data/ms-medicare-ro/abg_hrr.tsv')

medicare_state_use = read_tsv('../data/ms-medicare-ro/ineq_medicare_state.tsv')
medicare_hrr_use = read_tsv('../data/ms-medicare-ro/ineq_medicare_hrr.tsv')

medicare = bind_rows(
  inner_join(medicare_state_use, ro_state, by = c('drug_group', 'state')) %>%
    mutate(level = 'state', unit = state),
  inner_join(medicare_hrr_use, ro_hrr, by = c('drug_group', 'hrr')) %>%
    mutate(level = 'hrr', unit = as.character(hrr))
) %>%
  inner_join(ro_bugdrugs, by = c('bug', 'drug_group')) %>%
  mutate(pct_res = 100 * f_ns,
         did = us_europe_convert(drug_group, total_use * 1000)) %>%
  select(level, bug, drug = drug_group, unit, did, pct_res)
```

To the eye, it looks like the state and HRR points lie on similar lines:

```{r medicare_levels_plot}
medicare %>%
  ggplot(aes(did, pct_res, color = level)) +
  facet_wrap(~ bug + drug, scales = 'free_x') +
  geom_point() +
  geom_smooth(method = 'lm')
```

Looking at just the regression results emphasizes that:

```{r}
medicare %>%
  nest(unit, did, pct_res) %>%
  mutate(model = map(data, ~ lm(pct_res ~ did, data = .)),
         slope = map_dbl(model, ~ coef(.)['did']),
         conf.low = map_dbl(model, ~ confint(.)['did', 1]),
         conf.high = map_dbl(model, ~ confint(.)['did', 2])) %>%
  ggplot(aes(level, slope, ymin = conf.low, ymax = conf.high)) +
  facet_wrap(~ bug + drug) +
  geom_point() +
  geom_errorbar()
```

And I could do something more sophisticated, by running a model $\rho ~ \tau + \tau \times L$, where $L$ is a dummy variable encoding whether the level of the analysis is state or HRR. All those interaction terms are not statistically significant.

```{r}
medicare %>%
  mutate(level = as.integer(level == 'hrr')) %>%
  nest(level, unit, did, pct_res) %>%
  mutate(model = map(data, ~ lm(pct_res ~ did * level, data = .)),
         interaction_pval = map_dbl(model, ~ summary(.)$coefficients['did:level', 'Pr(>|t|)'])) %>%
  select(bug, drug, interaction_pval) %>%
  kable()
```

### ECDC

```{r ecdc}
rename_bug = function(x) {
  sapply(x, function(y) {
    switch(y, 'Escherichia coli'='E. coli', 'Streptococcus pneumoniae'='S. pneumoniae', y)
  })
}

ecdc = read_tsv('../data/ecdc/data.tsv') %>%
  mutate(bug = rename_bug(bug),
         pct_res = 100 * f_ns,
         dataset='ECDC') %>%
  select(dataset, bug, drug, geo_unit=country, did, n_resistant=n_ns, n_isolates, pct_res)
```

### NHSN/IMS

```{r nhsn_ims}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  mutate(dataset='NHSN/IMS', bug='E. coli', drug='quinolone',
         pct_res = 100 * n_resistant / n_isolates,
         did = us_europe_convert(drug, rx_1k_year)) %>%
  select(dataset, bug, drug, geo_unit=state, did, pct_res, n_isolates)
```

# Results

## MarketScan

```{r maup_db}
state_census = read_tsv('../db/census/state_census.tsv') %>%
  filter(between(year, 2011, 2014)) %>%
  group_by(state_abbreviation) %>%
  summarize(population = mean(population))

state_data = data_frame(
  unit = state.name,
  state_abbreviation = state.abb,
  region = state.region,
  division = state.division,
  long = state.center$x,
  lat = state.center$y
) %>%
  mutate_if(is.factor, as.character) %>%
  inner_join(state_census, by = 'state_abbreviation') %>%
  mutate(unit_id = 1:n())
```

```{r marketscan_maup_data}
marketscan_res = read_tsv('~/grad/proj/medicare/analysis/ms2/data/abg_state.tsv') %>%
  rename(drug=drug_group) %>%
  mutate(bugdrug = case_when(
    .$bug == 'E. coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'S. pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'S. pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  filter(!is.na(bugdrug)) %>%
  mutate(n_resistant = as.integer(round(f_ns * n_isolates))) %>%
  select(bugdrug, drug, state, n_resistant, n_isolates)

marketscan_use = read_tsv('~/grad/proj/medicare/analysis/ms2/ineq_marketscan.tsv') %>%
  rename(drug = drug_group) %>%
  filter(drug %in% c('quinolone', 'beta_lactam', 'macrolide')) %>%
  mutate(did = us_europe_convert(drug, total_use * 1000))

marketscan = marketscan_use %>%
  inner_join(marketscan_res, by=c('drug', 'state')) %>%
  rename(unit = state) %>%
  left_join(select(state_data, unit, population), by = 'unit') %>%
  select(unit, bugdrug, did, n_resistant, n_isolates, population)
```

```{r marketscan_maup_setup}
# group n items into k groups, with at least 1 item in each group
sample1 = function(n, k) {
  stopifnot(n >= k)
  sample(c(1:k, sample(k, n - k, replace = TRUE)))
}

renumber = function(x) match(x, unique(x))

# given distances between things, create groups
random_zones = function(distances, k) {
  stopifnot(nrow(distances) == ncol(distances))
  stopifnot(nrow(distances) >= k)
  
  centers = sample(1:nrow(distances), k)
  zones = distances[, centers] %>%
    apply(1, function(x) centers[which.min(x)])
  
  renumber(zones)
}

verify_unit_data = function(unit_data) {
  stopifnot(all(c('unit', 'long', 'lat') %in% names(unit_data)))
  if (any(duplicated(unit_data$unit))) stop('duplicated units')
}

deg2rad = function(deg) deg * pi / 180

haversine = function(long1, lat1, long2, lat2, R = 1.0) {
  long1 = deg2rad(long1)
  lat1 = deg2rad(lat1)
  long2 = deg2rad(long2)
  lat2 = deg2rad(lat2)
  R * acos(pmin(1.0, sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(long2 - long1)))
}

unit_distances = function(unit_data) {
  verify_unit_data(unit_data)
  units = unit_data$unit
  n_units = length(units)
  
  unit_data %>%
    crossing(., .) %>%
    arrange(unit, unit1) %>%
    mutate(dist = haversine(long, lat, long1, lat1)) %$%
    matrix(dist, ncol = n_units, nrow = n_units) %>%
    set_rownames(units) %>%
    set_colnames(units)
}
```

```{r maup_helper_functions}
random_group = function(group_type, unit_distances, k) {
  if (group_type == 'sample') {
    sample1(nrow(unit_distances), k)
  } else if (group_type == 'zone') {
    random_zones(unit_distances, k)
  } else {
    stop('control flow error')
  }
}

aggregate = function(df, group) {
  mutate(df, group = group) %>%
    group_by(group) %>%
    summarize(did = weighted.mean(did, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           pct_res = n_resistant / n_isolates * 100)
}

try_load = function(fn, expr, force_run = FALSE) {
  if (!force_run && file.exists(fn)) {
    read_rds(fn)
  } else {
    value = expr
    write_rds(value, fn)
  }
}
```

```{r marketscan_maup_compute}
# create a hierarchical list: marketscan_maup_data$`Ec/q`$data
marketscan_maup_data = marketscan %>%
  nest(-bugdrug) %>%
  mutate(
    state_id = map(data, ~ match(.$unit, state.name)),
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

maup_group = function(maup_data, k, group_type) {
  switch(group_type,
         'sample' = sample1(maup_data$n_units, k),
         'zone' = random_zones(maup_data$unit_distances, k),
         'region' = renumber(state.region[maup_data$state_id]),
         'division' = renumber(state.division[maup_data$state_id]),
         'state' = maup_data$state_id
  )
}

n_iterations = 100

marketscan_canonical = crossing(
  bugdrug = marketscan$bugdrug,
  group_type = c('region', 'division', 'state')
)

marketscan_maup = try_load('results/marketscan_maup.rds', {
  crossing(
    bugdrug = marketscan$bugdrug,
    k1 = c(4, 9, 20, 30),
    group_type = c('sample', 'zone'),
    iteration = 1:n_iterations
  ) %>%
    bind_rows(marketscan_canonical) %>%
    mutate(
      group = pmap(list(bugdrug, k1, group_type), ~ maup_group(marketscan_maup_data[[..1]], ..2, ..3)),
      k = map_int(group, ~ length(unique(.))),
      group_data = map2(bugdrug, group, ~ aggregate(marketscan_maup_data[[.x]]$data, .y)),
      group_type = if_else(group_type %in% c('state', 'region', 'division'), 'canonical', group_type),
      # regular linear models
      linear_model = map(group_data, ~ lm(pct_res ~ did, data = .)),
      slope = map_dbl(linear_model, ~ coef(.)['did']),
      # weighted linear models
      weighted_linear_model = map(group_data, ~ lm(pct_res ~ did, data = ., weights = n_isolates)),
      weighted_slope = map_dbl(weighted_linear_model, ~ coef(.)['did']),
      # logistic regression
      logistic_model = map(group_data, ~ glm(cbind(n_resistant, n_susceptible) ~ did, data = ., family = 'binomial')),
      log_odds_ratio = map_dbl(logistic_model, ~ coef(.)['did']),
      # Spearman correlation
      cor_model = map(group_data, ~ cor.test(.$pct_res, .$did, method = 'spearman')),
      cor = map_dbl(cor_model, ~ .$estimate)
    )
}, force_run = TRUE)
```

```{r marketscan_maup_plot}
marketscan_maup %>%
  group_by(k, group_type, bugdrug) %>%
  summarize(mean = mean(slope),
            cil = quantile(slope, 0.25),
            ciu = quantile(slope, 0.75)) %>%
  ggplot(aes(factor(k), mean, color = group_type)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = cil, ymax = ciu), position = position_dodge(width = 0.5), width = 0.5)

marketscan_maup %>%
  select(bugdrug, k, group_type, cor, slope, log_odds_ratio) %>%
  gather('metric', 'value', cor, slope, log_odds_ratio) %>%
  ggplot(aes(factor(k), value, color = group_type)) +
  facet_wrap(~ bugdrug + metric, scales = 'free') +
  geom_violin()
```

```{r extremal_slopes}
marketscan_maup_ext = marketscan_maup %>%
  group_by(bugdrug, k, group_type) %>%
  filter(slope %in% c(min(slope), max(slope))) %>%
  mutate(extremum = if_else(slope == max(slope), 'max', 'min')) %>%
  ungroup() %>%
  mutate(unit = map(bugdrug, ~ marketscan_maup_data[[.]]$data$unit))

marketscan_maup_ext %>%
  filter(group_type != 'canonical') %>%
  select(bugdrug, k, group_type, group_data, extremum) %>%
  unnest() %>%
  ggplot(aes(did, pct_res, color = extremum)) +
  facet_grid(k ~ bugdrug + group_type, scales = 'free') +
  geom_hline(yintercept = 0.0, color = 'gray') +
  geom_point() +
  geom_smooth(method = 'lm') +
  theme_classic()
```

```{r extremal_maps}
hex_map = read_tsv('~/grad/db/us_hex.tsv')

marketscan_maup_ext %>%
  filter(k == 4) %>%
  select(bugdrug, unit, group, group_type, extremum) %>%
  unnest() %>%
  left_join(hex_map, by = c('unit' = 'state')) %>%
  ggplot(aes(x, y)) +
  facet_grid(bugdrug ~ group_type + extremum) +
  geom_polygon(aes(group = unit, fill = factor(group))) +
  geom_polygon(data = hex_map, aes(group = state), color = 'black', fill = NA) +
  scale_fill_brewer(palette = 'Accent') +
  theme_void() +
  theme(legend.position = 'none') +
  ggtitle('k = 4')

marketscan_maup_ext %>%
  filter(k == 9) %>%
  select(bugdrug, unit, group, group_type, extremum) %>%
  unnest() %>%
  left_join(hex_map, by = c('unit' = 'state')) %>%
  ggplot(aes(x, y)) +
  facet_grid(bugdrug ~ group_type + extremum) +
  geom_polygon(aes(group = unit, fill = factor(group))) +
  geom_polygon(data = hex_map, aes(group = state), color = 'black', fill = NA) +
  theme_void() +
  theme(legend.position = 'none') +
  ggtitle('k = 9')

marketscan_maup_ext %>%
  filter(k == 20) %>%
  select(bugdrug, unit, group, group_type, extremum) %>%
  unnest() %>%
  left_join(hex_map, by = c('unit' = 'state')) %>%
  ggplot(aes(x, y)) +
  facet_grid(bugdrug ~ group_type + extremum) +
  geom_polygon(aes(group = unit, fill = factor(group))) +
  geom_polygon(data = hex_map, aes(group = state), color = 'black', fill = NA) +
  theme_void() +
  theme(legend.position = 'none') +
  ggtitle('k = 20')
```

## IMS/NHSN CAUTIs

**swo** refactor functions to match marketscan

```{r nhsn}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  rename(state_abbreviation = state) %>%
  filter(state_abbreviation %in% state.abb) %>%
  mutate(state_id = match(state_abbreviation, state.abb),
         unit = state.name[state_id],
         bugdrug = 'Ec/q',
         did = us_europe_convert('quinolone', rx_1k_year)) %>%
  arrange(unit) %>%
  left_join(select(state_data, unit, population), by = 'unit') %>%
  select(unit, bugdrug, did, n_resistant, n_isolates, population)

nhsn_maup_data = nhsn %>%
  nest(-bugdrug) %>%
  mutate(
    state_id = map(data, ~ match(.$unit, state.name)),
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

nhsn_canonical = crossing(
  bugdrug = 'Ec/q',
  group_type = c('region', 'division', 'state')
)

ks = c(4, 9, 20, 30)

nhsn_maup = try_load('results/nhsn_maup.rds', {
  crossing(
    bugdrug = 'Ec/q',
    k1 = ks,
    group_type = c('sample', 'zone'),
    iteration = 1:n_iterations
  ) %>%
    bind_rows(nhsn_canonical) %>%
    mutate(
      group = pmap(list(bugdrug, k1, group_type), ~ maup_group(nhsn_maup_data[[..1]], ..2, ..3)),
      k = map_int(group, ~ length(unique(.))),
      group_data = map2(bugdrug, group, ~ aggregate(nhsn_maup_data[[.x]]$data, .y)),
      group_type = if_else(group_type %in% c('state', 'region', 'division'), 'canonical', group_type),
      # regular linear models
      linear_model = map(group_data, ~ lm(pct_res ~ did, data = .)),
      slope = map_dbl(linear_model, ~ coef(.)['did']),
      # weighted linear models
      weighted_linear_model = map(group_data, ~ lm(pct_res ~ did, data = ., weights = n_isolates)),
      weighted_slope = map_dbl(weighted_linear_model, ~ coef(.)['did']),
      # logistic regression
      logistic_model = map(group_data, ~ glm(cbind(n_resistant, n_susceptible) ~ did, data = ., family = 'binomial')),
      log_odds_ratio = map_dbl(logistic_model, ~ coef(.)['did']),
      # Spearman correlation
      cor_model = map(group_data, ~ cor.test(.$pct_res, .$did, method = 'spearman')),
      cor = map_dbl(cor_model, ~ .$estimate)
    )
}, force_run = TRUE)
```

```{r nhsn_maup_plot}
nhsn_maup %>%
  group_by(k, group_type) %>%
  summarize(mean = mean(slope),
            q25 = quantile(slope, 0.25),
            q75 = quantile(slope, 0.75)) %>%
  ggplot(aes(factor(k), mean, color = group_type)) +
  geom_point(position = position_dodge(width = 0.5)) +
  geom_errorbar(aes(ymin = q25, ymax = q75),
                position = position_dodge(width = 0.5), width = 0.5)

nhsn_maup %>%
  ggplot(aes(factor(k), slope, color = group_type)) +
  geom_boxplot()
```

## Europe

```{r europe_data}
europe_units = read_tsv('../db/europe_centers/europe_centers.tsv') %>%
  mutate(unit_id = 1:n()) %>%
  select(unit = country, long = longitude, lat = latitude, population, unit_id)

europe = read_tsv('../data/ecdc/data.tsv') %>%
  mutate(bugdrug = case_when(
    .$bug == 'Escherichia coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  rename(unit = country) %>%
  left_join(select(europe_units, unit, population), by ='unit') %>%
  select(unit, bugdrug, did, n_resistant = n_ns, n_isolates, population)
```

```{r europe_maup_compute}
europe_names = unique(europe$unit)

europe_maup_data = europe %>%
  nest(-bugdrug) %>%
  mutate(
    state_id = map(data, ~ match(.$unit, europe_names)),
    unit_data = map(data, ~ filter(europe_units, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

# swo: come up with a better name than "state"
europe_canonical = crossing(
  bugdrug = unique(europe$bugdrug),
  group_type = 'state'
)

# swo: improve this, so we have one function for all
europe_maup = try_load('results/europe_maup.rds', {
  crossing(
    bugdrug = unique(europe$bugdrug),
    k1 = c(4, 9, 20),
    group_type = c('sample', 'zone'),
    iteration = 1:n_iterations
  ) %>%
    bind_rows(europe_canonical) %>%
    mutate(
      group = pmap(list(bugdrug, k1, group_type), ~ maup_group(europe_maup_data[[..1]], ..2, ..3)),
      k = map_int(group, ~ length(unique(.))),
      group_data = map2(bugdrug, group, ~ aggregate(europe_maup_data[[.x]]$data, .y)),
      group_type = if_else(group_type %in% c('state', 'region', 'division'), 'canonical', group_type),
      # regular linear models
      linear_model = map(group_data, ~ lm(pct_res ~ did, data = .)),
      slope = map_dbl(linear_model, ~ coef(.)['did']),
      # weighted linear models
      weighted_linear_model = map(group_data, ~ lm(pct_res ~ did, data = ., weights = n_isolates)),
      weighted_slope = map_dbl(weighted_linear_model, ~ coef(.)['did']),
      # logistic regression
      logistic_model = map(group_data, ~ glm(cbind(n_resistant, n_susceptible) ~ did, data = ., family = 'binomial')),
      log_odds_ratio = map_dbl(logistic_model, ~ coef(.)['did']),
      # Spearman correlation
      cor_model = map(group_data, ~ cor.test(.$pct_res, .$did, method = 'spearman')),
      cor = map_dbl(cor_model, ~ .$estimate)
    )
}, force_run = TRUE)
```

```{r europe_maup_plot}
europe_maup %>%
  group_by(k, group_type, bugdrug) %>%
  summarize(mean = mean(slope),
            q25 = quantile(slope, 0.25),
            q75 = quantile(slope, 0.75)) %>%
  ggplot(aes(factor(k), mean, color = group_type)) +
  geom_point(position = position_dodge(width = 0.5)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_errorbar(aes(ymin = q25, ymax = q75),
                position = position_dodge(width = 0.5), width = 0.5)

europe_maup %>%
  ggplot(aes(factor(k), slope, color = group_type)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_boxplot()
```
