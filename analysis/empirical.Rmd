---
title: "Empirical use-resistance relationships over geographic scales"
author: "Scott Olesen"
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  fig.width=7, fig.height=4, fig.path='fig/',
  dev=c('png', 'pdf'),
  echo=FALSE, warning=FALSE, message=FALSE,
  cache=TRUE, autodep=TRUE)
pdf.options(useDingbats=FALSE, useKerning=FALSE)

library(purrr)
```

# To do

- Weighted regressions?
- Correlations and slopes
- Use haversine for groupings
- Cite that guy for European centers?

# Methods

## US/Europe conversions

Most of the US studies and data are measured in prescriptions (or claims) per 1,000 people per year (PIY); the European studies are usually in DID (DDD per 1,000 people per year). Converting between the two requires asserting how many DDD are in one prescription.

I got these numbers by (1) looking in MarketScan and computing the average days' supply for claims for each drug and (2) comparing the CDDEP's within-US numbers (in PIY) with their across-country values for the US (in DID). They seem to disagree somewhat on the $\beta$-lactams. Something to be looked into a little more.

```{r piy_did}
us_europe_crosswalk = data_frame(
  drug = c('beta_lactam', 'quinolone', 'macrolide'),
  ddd_per_rx = c(10, 10, 7)
)

kable(us_europe_crosswalk)

# PIY = Prescriptions per 1,000 Inhabitants per Year
us_europe_convert = function(drug_, piy) {
  us_europe_crosswalk %$%
    { piy / 365 * ddd_per_rx[match(drug_, drug)] }
}
```

## Data

#### Medicare & ResistanceOpen

This is a nice chance to ask if going to a smaller scale gives you different regression coefficients. I compare the slopes of the use/resistance relationship when using HRRs and states.

```{r medicare_ro}
ro_bugdrugs = data_frame(
  bug = c('S. pneumoniae', 'S. pneumoniae', 'E. coli'),
  drug_group = c('beta_lactam', 'macrolide', 'quinolone')
)

ro_state = read_tsv('../data/ms-medicare-ro/abg_state.tsv')
ro_hrr = read_tsv('../data/ms-medicare-ro/abg_hrr.tsv')

medicare_state_use = read_tsv('../data/ms-medicare-ro/ineq_medicare_state.tsv')
medicare_hrr_use = read_tsv('../data/ms-medicare-ro/ineq_medicare_hrr.tsv')

medicare_state = inner_join(medicare_state_use, ro_state, by=c('drug_group', 'state')) %>%
  inner_join(ro_bugdrugs) %>%
  mutate(dataset='Medicare (state)',
         pct_res=100*f_ns,
         did = us_europe_convert(drug_group, total_use * 1000)) %>%
  select(dataset, bug, drug=drug_group, geo_unit=state, did, pct_res)

medicare_hrr = inner_join(medicare_hrr_use, ro_hrr, by=c('drug_group', 'hrr')) %>%
  inner_join(ro_bugdrugs) %>%
  mutate(dataset='Medicare (HRR)',
         pct_res=100*f_ns,
         did = us_europe_convert(drug_group, total_use * 1000),
         geo_unit = as.character(hrr)
         ) %>%
  select(dataset, bug, drug=drug_group, geo_unit, did, pct_res)

medicare_state_models = medicare_state %>%
  group_by(bug, drug) %>%
  do(tidy(lm(pct_res ~ did, data=.), conf.int=TRUE)) %>%
  ungroup()

medicare_hrr_models = medicare_hrr %>%
  group_by(bug, drug) %>%
  do(tidy(lm(pct_res ~ did, data=.), conf.int=TRUE)) %>%
  ungroup()
```

To the eye, it looks like the state and HRR points lie on similar lines:

```{r}
bind_rows(
  medicare_state %>% mutate(level='state'),
  medicare_hrr %>% mutate(level='hrr')
) %>%
  ggplot(aes(did, pct_res, color=level)) +
  facet_wrap(~ bug + drug, scales='free_x') +
  geom_point() +
  geom_smooth(method='lm')
```

Looking at just the regression results emphasizes that:

```{r}
bind_rows(
  medicare_state_models %>% mutate(level='state'),
  medicare_hrr_models %>% mutate(level='hrr')
) %>%
  filter(term == 'did') %>%
  ggplot(aes(level, estimate, ymin=conf.low, ymax=conf.high)) +
  facet_wrap(~ bug + drug) +
  geom_point() +
  geom_errorbar()
```

And I could do something more sophisticated, by running a model $\rho ~ \tau$ and another one $\rho ~ \tau + \tau \times L$, where $L$ is a dummy variable encoding whether the level of the analysis is state or HRR. All those interaction terms are not statistically significant.

```{r}
bind_rows(
  medicare_state %>% mutate(level='state'),
  medicare_hrr %>% mutate(level='hrr')
) %>%
  mutate(at_hrr = as.integer(level == 'hrr')) %>%
  group_by(bug, drug) %>%
  do(tidy(lm(did ~ pct_res * at_hrr, data=.), conf.int=TRUE)) %>%
  select(-std.error, -statistic) %>%
  filter(term == 'pct_res:at_hrr')
```

### ECDC

```{r ecdc}
rename_bug = function(x) {
  sapply(x, function(y) {
    switch(y, 'Escherichia coli'='E. coli', 'Streptococcus pneumoniae'='S. pneumoniae', y)
  })
}

ecdc = read_tsv('../data/ecdc/data.tsv') %>%
  mutate(bug = rename_bug(bug),
         pct_res = 100 * f_ns,
         dataset='ECDC') %>%
  select(dataset, bug, drug, geo_unit=country, did, n_resistant=n_ns, n_isolates, pct_res)
```

### NHSN/IMS

```{r nhsn_ims}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  mutate(dataset='NHSN/IMS', bug='E. coli', drug='quinolone',
         pct_res = 100 * n_resistant / n_isolates,
         did = us_europe_convert(drug, rx_1k_year)) %>%
  select(dataset, bug, drug, geo_unit=state, did, pct_res, n_isolates)
```

# Results

## MAUP

### MarketScan

```{r maup_db}
state_census = read_tsv('../db/census/state_census.tsv') %>%
  filter(between(year, 2011, 2014)) %>%
  group_by(state_abbreviation) %>%
  summarize(population = mean(population))

state_data = data_frame(
  state = state.name,
  state_abbreviation = state.abb,
  region = state.region,
  division = state.division,
  long = state.center$x,
  lat = state.center$y
) %>%
  mutate_if(is.factor, as.character) %>%
  inner_join(state_census, by = 'state_abbreviation') %>%
  mutate(unit_id = 1:n())
```

```{r marketscan_maup_data}
marketscan_res = read_tsv('~/grad/proj/medicare/analysis/ms2/data/abg_state.tsv') %>%
  rename(drug=drug_group) %>%
  mutate(bugdrug = case_when(
    .$bug == 'E. coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'S. pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'S. pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  filter(!is.na(bugdrug)) %>%
  mutate(n_resistant = as.integer(round(f_ns * n_isolates))) %>%
  select(bugdrug, drug, state, n_resistant, n_isolates)

marketscan_use = read_tsv('~/grad/proj/medicare/analysis/ms2/ineq_marketscan.tsv') %>%
  rename(drug = drug_group) %>%
  filter(drug %in% c('quinolone', 'beta_lactam', 'macrolide')) %>%
  mutate(did = us_europe_convert(drug, total_use * 1000))

marketscan = marketscan_use %>%
  inner_join(marketscan_res, by=c('drug', 'state')) %>%
  select(unit = state, bugdrug, did, n_resistant, n_isolates)
```

```{r marketscan_maup_random}
# group n items into k groups, with at least 1 item in each group
sample1 = function(n, k) {
  stopifnot(n >= k)
  sample(c(1:k, sample(k, n - k, replace = TRUE)))
}

range1 = function(x) max(x) - min(x)

maup_sim = function(ur, unit_data, ks, n_iterations=10, extra_groups=NULL) {
  if (!all(c('unit', 'long', 'lat', 'population') %in% names(unit_data))) {
    stop('missing columns in unit_data')
  }
  if (any(duplicated(unit_data$unit))) stop('duplicated units')
  if (!all(c('unit', 'bugdrug', 'did', 'n_resistant', 'n_isolates') %in% names(ur))) {
    stop('missing columns in use-resistance (ur)')
  }
  
  n_units = nrow(unit_data)
  if (max(ks) > n_units) stop('at least one k is greater than no. units')
  
  if (!is.null(extra_groups)) {
    if (!all(c('k', 'type', 'group') %in% names(extra_groups))) {
      stop('missing columns in extra_groups')
    }
  }
  
  bugdrugs = unique(ur$bugdrug)

  random_samples = function(k) {
    samples = as.character(sample1(n_units, k))
    data_frame(unit = unit_data$unit, group = samples)
  }

  unit_distances = unit_data %>%
    select(long, lat) %>%
    dist() %>%
    as.matrix() %>%
    set_colnames(unit_data$unit) %>%
    set_rownames(unit_data$unit)

  random_zones = function(k) {
    centers = sample(unit_data$unit, k)
    zones = unit_distances[, centers] %>%
      apply(1, function(x) centers[which.min(x)])
    
    data_frame(unit = unit_data$unit, group = zones)
  }
  
  data_f = function(bugdrug_, group_) {
    ur %>%
      left_join(unit_data, by = 'unit') %>%
      filter(bugdrug == bugdrug_) %>%
      left_join(group_, by = 'unit') %>%
      group_by(group) %>%
      summarize(pct_res = sum(n_resistant) / sum(n_isolates) * 100,
                did = weighted.mean(did, w = population))
  }
  
  # iterations for each k
  k_it = crossing(k = ks, iteration = 1:n_iterations)
  
  # add in the sample and zone
  bind_rows(
    k_it %>% mutate(type = 'sample', group = map(k, random_samples)),
    k_it %>% mutate(type = 'zone', group = map(k, random_zones))
  ) %>%
    bind_rows(extra_groups) %>%
    crossing(bugdrug = bugdrugs) %>%
    mutate(data = map2(bugdrug, group, data_f),
           model = map(data, ~ lm(pct_res ~ did, data = .)),
           slope = map_dbl(model, ~ coef(.)[2]),
           cor = map_dbl(data, ~ cor(.$did, .$pct_res)),
           did_range = map_dbl(data, ~ range1(.$did)),
           res_range = map_dbl(data, ~ range1(.$pct_res)))
}
```

```{r}
marketscan_unit_data = state_data %>%
  rename(unit = state) %>%
  filter(unit %in% marketscan$unit)

state_grouping = data_frame(
  k = n_units,
  group = map(1, ~ select(unit_data, unit, group = unit_id))
)

division_grouping = data_frame(
  k = length(unique(unit_data$division)),
  group = map(1, ~ select(unit_data, unit, group = division))
)

region_grouping = data_frame(
  k = length(unique(unit_data$region)),
  group = map(1, ~ select(unit_data, unit, group = region))
)

census_groups = bind_rows(state_grouping, division_grouping, region_grouping) %>%
  mutate(type = 'actual')

marketscan_ks = c(4, 9, 20, 30, 40)
marketscan_maup = maup_sim(marketscan, marketscan_unit_data, marketscan_ks,
                           extra_groups = census_groups)
```

```{r}
marketscan_maup %>%
  select(k, iteration, type, bugdrug, slope, cor) %>%
  gather('metric', 'estimate', slope, cor) %>%
  ggplot(aes(factor(k), estimate, color=type)) +
  geom_boxplot() +
  geom_jitter() +
  facet_wrap(metric ~ bugdrug, scales='free_y')

# swo:
# - add invisible data to get all factor levels
# - only THEN plot the "actual" data, w/o boxplots

ex4 = marketscan_maup %>%
  filter(k == 4, type == 'zone') %>%
  group_by(bugdrug) %>%
  filter(cor %in% c(min(cor), max(cor))) %>%
  mutate(extremum = if_else(cor == max(cor), 'max', 'min')) %>%
  ungroup()

ex4 %>%
  select(bugdrug, extremum, data) %>%
  unnest() %>%
  ggplot(aes(did, pct_res)) +
  geom_point() +
  stat_smooth(method = 'lm', se = FALSE) +
  facet_grid(extremum ~ bugdrug, scales='free')
  
map_f = function(group_) {
  state_map %>%
    left_join(group_, by = 'unit') %>%
    ggplot(aes(long, lat, group = map_group, fill = group)) +
    geom_polygon(color = 'black') +
    coord_map() +
    theme(legend.position = 'none',
          axis.title.x = element_blank(),
          axis.title.y = element_blank())
}

ex4 %>%
  mutate(plot = map(group, map_f)) %>%
  pull(plot) %>%
  { ggpubr::ggarrange(plotlist = .) }
```

### Using IMS/NHSN

```{r}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  rename(state_abbreviation = state) %>%
  filter(state_abbreviation %in% state.abb) %>%
  mutate(state_id = match(state_abbreviation, state.abb),
         state = state.name[state_id],
         bugdrug = 'Ec/q',
         did = us_europe_convert('quinolone', rx_1k_year)) %>%
  select(unit = state, bugdrug, did, n_resistant, n_isolates)

nhsn_unit_data = state_data %>%
  rename(unit = state) %>%
  filter(unit %in% nhsn$unit)

nhsn_extra_groups = data_frame(
  k = 50,
  type = 'actual',
  group = map(1, ~ select(nhsn_unit_data, unit, group = unit_id))
)

nhsn_maup = maup_sim(nhsn, nhsn_unit_data, c(4, 9, 20, 30, 40),
                     extra_groups = nhsn_extra_groups)
```

```{r}
nhsn_maup %>%
  select(k, iteration, type, bugdrug, slope, cor) %>%
  gather('metric', 'estimate', slope, cor) %>%
  ggplot(aes(factor(k), estimate, color=type)) +
  geom_boxplot() +
  geom_jitter() +
  facet_wrap(metric ~ bugdrug, scales='free_y')
```

### Europe

```{r}
europe = read_tsv('../data/ecdc/data.tsv') %>%
  mutate(bugdrug = case_when(
    .$bug == 'Escherichia coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  left_join(select(europe_centers, country, population), by='country') %>%
  select(unit = country, bugdrug, did, n_resistant = n_ns, n_isolates)

europe_units = read_tsv('../db/europe_centers/europe_centers.tsv') %>%
  filter(country %in% europe$unit) %>%
  mutate(unit_id = 1:n()) %>%
  select(unit = country, long = longitude, lat = latitude, population, unit_id)

europe_extra = data_frame(
  k = nrow(europe_units),
  type = 'actual',
  group = map(1, ~ select(europe_units, unit, group = unit_id))
)

europe_maup = maup_sim(europe, europe_units, ks = c(5, 10, 15, 20),
                       extra_groups = europe_extra)
```

```{r}
europe_maup %>%
  select(k, iteration, type, bugdrug, slope, cor) %>%
  gather('metric', 'estimate', slope, cor) %>%
  ggplot(aes(factor(k), estimate, color=type)) +
  geom_boxplot() +
  geom_jitter() +
  facet_wrap(metric ~ bugdrug, scales='free_y')
```

### Simulations

Here I imagine I have $N = 50$ states with uses uniformly distributed between 0 and $u_\mathrm{max} = 1$. Some slope $m \in [0, 0.1, 1, 10]$ connects use with resistance, which is subject to variance $\sigma = 1$. If I randomly aggregate or zone states into $k$ groups, averaging use and resistance in each group, how do the measured use-resistance slopes $\hat{m}$ compare to the actual $m$?

Both types of aggregation appear to give unbiased estimates for $m$. The variance of the random aggregates increases with the size of the aggregates, but only substantially so for small $k$. The standard errors in the measured slopes increases for both zones and random samples, but the effect is especially acute for the random samples. This makes it look like going to larger aggregates is a pretty bad way to find a use-resistance relationship!

```{r maup_abstract_sim}
which_nearest = function(x, vals) {
  outer(x, vals, FUN=function(x, y) abs(x - y)) %>%
    apply(1, which.min)
}

sim_lm = function(slope, k, n_units=50, use_max=1, sigma=1) {
  use = runif(n_units, 0, use_max)
  res = use * slope + rnorm(n_units, 0, sigma)
  
  # random sample grouping
  sample_group = sample1(n_units, k)
  sample_model = data_frame(use=use, res=res, g=sample_group) %>%
    group_by(g) %>%
    summarize_at(vars(use, res), mean) %>%
    lm(res ~ use, data=.) %>%
    tidy(conf.int=TRUE) %>%
    mutate(type = 'sample')
  
  # random zone grouping
  centers = sample(use, size = k, replace = FALSE)
  zones = which_nearest(use, centers)
  zone_model = data_frame(use=use, res=res, g=zones) %>%
    group_by(g) %>%
    summarize_at(vars(use, res), mean) %>%
    lm(res ~ use, data=.) %>%
    tidy(conf.int=TRUE) %>%
    mutate(type = 'zone')
  
  bind_rows(sample_model, zone_model)
}

sim_group = crossing(k = c(5, 10, 25, 50),
         slope = c(0, 0.1, 1, 10),
         iteration = 1:100) %>%
  group_by_all() %>%
  do(sim_lm(.$slope, .$k)) %>%
  ungroup()
```

```{r}
sim_group %>%
  filter(term == 'use') %>%
  ggplot(aes(factor(k), estimate)) +
  geom_hline(aes(yintercept = slope), color='gray') +
  geom_boxplot(aes(color=type)) +
  facet_wrap(~ slope, scales='free_y')
```
