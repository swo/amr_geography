---
title: "Empirical use-resistance relationships over geographic scales"
author: "Scott Olesen"
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 4, fig.path = 'fig/',
  dev = c('png', 'pdf'), 
  echo = FALSE, warning = FALSE, message = FALSE,
  cache = TRUE, autodep = TRUE)

pdf.options(useDingbats = FALSE, useKerning = FALSE)

map = purrr::map
```

# Methods

## Data

### MarketScan

```{r maup_db}
state_data = read_tsv('../db/state_census.tsv') %>%
  rename(us_region = region, us_division = division)
```

```{r marketscan_data}
marketscan_res = read_tsv('~/grad/proj/medicare/analysis/ms2/data/abg_state.tsv') %>%
  rename(drug = drug_group) %>%
  mutate(bugdrug = case_when(
    .$bug == 'E. coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'S. pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'S. pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  filter(!is.na(bugdrug)) %>%
  mutate(n_resistant = as.integer(round(f_ns * n_isolates))) %>%
  select(bugdrug, drug, state, n_resistant, n_isolates)

marketscan_use = read_tsv('~/grad/proj/medicare/analysis/ms2/ineq_marketscan.tsv') %>%
  rename(drug = drug_group, use = total_use) %>%
  filter(drug %in% c('quinolone', 'beta_lactam', 'macrolide'))

marketscan = marketscan_use %>%
  inner_join(marketscan_res, by = c('drug', 'state')) %>%
  rename(unit = state) %>%
  left_join(state_data, by = 'unit') %>%
  select(unit_id, unit, bugdrug, use, n_resistant, n_isolates, population)
```

### NHSN/IMS

```{r nhsn_ims}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  rename(state_abbreviation = state) %>%
  filter(state_abbreviation %in% state.abb) %>%
  mutate(unit_id = match(state_abbreviation, state.abb),
         bugdrug = 'Ec/q',
         use = rx_1k_year / 1e3) %>%
  arrange(unit_id) %>%
  left_join(state_data, by = 'unit_id') %>%
  select(unit_id, unit, bugdrug, use, n_resistant, n_isolates, population)
```

### ECDC

For the European data, we convert to "treatments" per person per year, assuming a certain conversion from DDD to treatments. This is just an *ad hoc* adjustment to get the European data to the same scales as used in the simulations and the US data.

```{r ecdc_convert}
did_cpy_map = data_frame(
  drug = c('beta_lactam', 'quinolone', 'macrolide'),
  ddd_per_tx = c(10, 10, 7),
  cpy_per_did = 365 / (1e3 * ddd_per_tx)
)

did_cpy_map %>%
  kable(caption = 'DDD to treatment conversion')
```

```{r ecdc}
europe_units = read_tsv('../db/europe_units.tsv') %>%
  select(unit_id, unit = country, long = longitude, lat = latitude, population, eu_region = region_name)

europe = read_tsv('../data/ecdc/data.tsv') %>%
  left_join(did_cpy_map, by = 'drug') %>%
  mutate(use = cpy_per_did * did) %>%
  mutate(bugdrug = case_when(
    .$bug == 'Escherichia coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  rename(unit = country) %>%
  left_join(europe_units, by = 'unit') %>%
  select(unit_id, unit, bugdrug, use, n_resistant = n_ns, n_isolates, population)

europe_names = unique(europe$unit)
```

# Results

## MarketScan

```{r marketscan_maup_setup}
# group n items into k groups, with at least n_min items in each group
sample_nmin = function(n, k, n_min = 2) {
  stopifnot(n_min * k <= n)
  sample(c(rep(1:k, each = n_min), sample(1:k, n - (n_min * k), replace = TRUE)))
}

renumber = function(x) match(x, unique(x))

# given distances between things, create groups
random_zones = function(distances, k) {
  stopifnot(nrow(distances) == ncol(distances))
  stopifnot(nrow(distances) >= k)
  
  centers = sample(1:nrow(distances), k)
  zones = distances[, centers] %>%
    apply(1, function(x) centers[which.min(x)])
  
  renumber(zones)
}

# wrapper around random zones, to ensure group size
random_zones_nmin = function(distances, k, n_min = 2, max_tries = 1e2) {
  try = 1
  while (try < max_tries) {
    z = random_zones(distances, k)
    if (min(table(z)) >= n_min) return(z)
    try = try + 1
  }
  
  NULL
}

deg2rad = function(deg) deg * pi / 180

haversine = function(long1, lat1, long2, lat2, R = 6371) {
  long1 = deg2rad(long1)
  lat1 = deg2rad(lat1)
  long2 = deg2rad(long2)
  lat2 = deg2rad(lat2)
  R * acos(pmin(1.0, sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(long2 - long1)))
}

unit_distances = function(unit_data) {
  stopifnot(all(c('unit', 'long', 'lat') %in% names(unit_data)))
  if (any(duplicated(unit_data$unit))) stop('duplicated units')

  units = unit_data$unit
  n_units = length(units)
  
  unit_data %>%
    crossing(., .) %>%
    arrange(unit, unit1) %>%
    mutate(dist = haversine(long, lat, long1, lat1)) %$%
    matrix(dist, ncol = n_units, nrow = n_units) %>%
    set_rownames(units) %>%
    set_colnames(units)
}
```

```{r maup_helper_functions}
odds = function(p) p / (1 - p)

aggregate = function(df, group) {
  mutate(df, group = group) %>%
    group_by(group) %>%
    summarize(use = weighted.mean(use, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           res = n_resistant / n_isolates,
           lores = log(odds(res)))
}

try_load = function(fn, expr, force_run = FALSE) {
  if (!force_run && file.exists(fn)) {
    read_rds(fn)
  } else {
    value = expr
    write_rds(value, fn)
  }
}
```

```{r marketscan_maup_compute}
# create a hierarchical list: marketscan_maup_data$`Ec/q`$data
marketscan_maup_data = marketscan %>%
  nest(-bugdrug) %>%
  mutate(
    #state_id = map(data, ~ match(.$unit, state.name)),
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

# swo: could put the region, etc. data right in to the maup data, so that it's not floating around
# in multiple places

maup_group = function(maup_data, k, group_type) {
  switch(group_type,
         'sample' = sample_nmin(maup_data$n_units, k),
         'zone' = random_zones_nmin(maup_data$unit_distances, k),
         'us_state' = maup_data$data$unit_id,
         'us_division' = renumber(state.division[maup_data$data$unit_id]),
         'us_region' = renumber(state.region[maup_data$data$unit_id]),
         'eu_country' = maup_data$data$unit_id,
         'eu_region' = renumber(europe_units$eu_region[maup_data[[.y]]$state_id])
  )
}

marketscan_canonical = crossing(
  bugdrug = marketscan$bugdrug,
  group_type = c('us_state', 'us_division', 'us_region')
)

# swo: this code down here seems really redundant with what's above

add_canonical_data = function(df, maup_data) {
  df %>%
    mutate(group = map2(group_type, bugdrug,
                        ~ switch(.x,
                                 'us_state' = maup_data[[.y]]$data$unit_id,
                                 'us_division' = renumber(state.division[maup_data[[.y]]$data$unit_id]),
                                 'us_region' = renumber(state.region[maup_data[[.y]]$data$unit_id]),
                                 'eu_country' = maup_data[[.y]]$data$unit_id,
                                 'eu_region' = renumber(europe_units$eu_region[maup_data[[.y]]$data$unit_id])
                                 )),
           k = map_int(group, ~ length(unique(.))))
}

canonical_types = c('us_state', 'us_region', 'us_division', 'eu_country', 'eu_region')

maup_sim = function(bugdrug, k, n_iterations, canonical_rows, maup_data) {
  crossing(
    bugdrug = bugdrug,
    k = k,
    group_type = c('sample', 'zone'),
    iteration = 1:n_iterations
  ) %>%
    mutate(group = pmap(list(bugdrug, k, group_type), ~ maup_group(maup_data[[..1]], ..2, ..3))) %>%
    bind_rows(add_canonical_data(canonical_rows, maup_data)) %>%
    mutate(
      group_data = map2(bugdrug, group, ~ aggregate(maup_data[[.x]]$data, .y)),
      canonical_type = if_else(group_type %in% canonical_types, group_type, NA_character_),
      group_type = if_else(group_type %in% canonical_types, 'canonical', group_type),
      model_arru = map(group_data, ~ lm(res ~ use, data = .)),
      model_loru = map(group_data, ~ lm(lores ~ use, data = .)),
      slope_arru = map_dbl(model_arru, ~ coef(.)['use']),
      slope_loru = map_dbl(model_loru, ~ coef(.)['use']) 
    )
}

marketscan_maup = maup_sim(
  bugdrug = marketscan$bugdrug,
  k = c(4, 9),
  n_iterations = 100,
  canonical_rows = marketscan_canonical,
  maup_data = marketscan_maup_data
)
```

### Canonical groupings

```{r marketscan_canonical}
canonical_grouping_plot = function(maup) {
  maup %>%
    filter(group_type == 'canonical') %>%
    select(bugdrug, canonical_type, data = group_data) %>%
    unnest() %>%
    ggplot(aes(use, res, color = canonical_type)) +
    facet_wrap(~ bugdrug, scales = 'free') +
    geom_smooth(aes(fill = canonical_type), method = 'lm', alpha = 0.1) +
    geom_point()
}

canonical_grouping_table = function(maup) {
  dataset = quo_name(enquo(maup))
  
  maup %>%
    filter(group_type == 'canonical') %>%
    mutate(
      slope_arru_cil = map_dbl(model_arru, ~ confint(.)['use', 1]),
      slope_arru_ciu = map_dbl(model_arru, ~ confint(.)['use', 2]),
      slope_loru_cil = map_dbl(model_loru, ~ confint(.)['use', 1]),
      slope_loru_ciu = map_dbl(model_loru, ~ confint(.)['use', 2])
    ) %>%
    select(bugdrug, canonical_type, starts_with('slope')) %>%
    mutate_if(is.numeric, ~ round(., 2)) %>%
    kable(caption = str_interp('slopes for canonical groupings (${dataset})'))
}

canonical_grouping_plot(marketscan_maup)
canonical_grouping_table(marketscan_maup)
```

### MAUP

```{r marketscan_maup_table}
maup_table = function(maup, canonical_base = 'us_state') {
  slopes = maup %>%
    select(bugdrug, k, group_type, canonical_type, starts_with('slope')) %>%
    gather('metric', 'slope', starts_with('slope'))
  
  base_slopes = slopes %>%
    filter(canonical_type == canonical_base) %>%
    select(bugdrug, metric, base_slope = slope)
  
  slopes %>%
    filter(group_type != 'canonical') %>%
    left_join(base_slopes, by = c('bugdrug', 'metric')) %>%
    mutate(slope_diff = slope - base_slope) %>%
    group_by(bugdrug, k, group_type, metric) %>%
    summarize(
      slope = list(slope),
      slope_diff = list(slope_diff),
      base_slope = unique(base_slope)
    ) %>%
    ungroup() %>%
    mutate(
      median_slope = map_dbl(slope, median),
      q25 = map_dbl(slope, ~ quantile(., 0.25)),
      q75 = map_dbl(slope, ~ quantile(., 0.75)),
      wilcox = map(slope_diff, ~ wilcox.test(., alternative = 'greater')),
      wilcox_p = map_dbl(wilcox, ~ .$p.value),
      wilcox_p_log10 = log10(wilcox_p),
      fdr = p.adjust(wilcox_p, 'BH') < 0.05
    ) %>%
    select(metric, bugdrug, group_type, k, base_slope, median_slope, q25, q75, wilcox_p, wilcox_p_log10, fdr) %>%
    arrange(metric, bugdrug, group_type, k) %>%
    mutate_if(is.numeric, ~ round(., 3)) %>%
    kable(caption = 'Comparing base and MAUP slopes')
}

maup_table(marketscan_maup)
```

Histogram of slopes over the random aggregates (zonal and sample) for each bug/drug and $k$. Dotted blue line shows the slope over the raw units (states).

```{r marketscan_maup_plot}
maup_plot = function(maup, canonical_base = 'us_state', metric = 'slope_arru') {
  metric_ = as.symbol(metric)
  
  dat = maup %>%
    filter(group_type != 'canonical') %>%
    select(bugdrug, k, group_type, !!metric_)
  
  slopes = maup %>%
    filter(canonical_type == canonical_base) %>%
    select(bugdrug, base_slope = !!metric_) %>%
    crossing(k = unique(dat$k))
  
  dat %>%
    ggplot(aes(!!metric_, fill = group_type)) +
    facet_grid(k ~ bugdrug, scales = 'free') +
    geom_vline(
      data = slopes,
      aes(xintercept = base_slope),
      color = 'blue', linetype = 2
    ) +
    geom_histogram(position = 'dodge') +
    xlab(str_interp('slope (${metric}) over random aggregate'))
}

maup_plot(marketscan_maup)
```

## IMS/NHSN CAUTIs

```{r nhsn}
nhsn_maup_data = nhsn %>%
  nest(-bugdrug) %>%
  mutate(
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

nhsn_canonical = crossing(
  bugdrug = 'Ec/q',
  group_type = c('us_region', 'us_division', 'us_state')
)

nhsn_maup = maup_sim(
  bugdrug = 'Ec/q',
  k = c(4, 9),
  n_iterations = 100,
  canonical_rows = nhsn_canonical,
  maup_data = nhsn_maup_data
)
```

### Canonical groupings

```{r nhsn_canonical}
canonical_grouping_plot(nhsn_maup)
canonical_grouping_table(nhsn_maup)
```

### MAUP

```{r nhsn_maup_table}
maup_table(nhsn_maup)
```

```{r nhsn_maup_plot}
maup_plot(nhsn_maup)
```

### Example regions

```{r hex}
hex_map = read_tsv('~/grad/db/us_hex.tsv') %>%
  filter(!is.na(state)) %>%
  rename(unit = state)

hex_labels = hex_map %>%
  filter(order %in% c(0, 3)) %>%
  group_by(unit) %>%
  summarize_at(c('x', 'y'), mean) %>%
  mutate(abb = state.abb[match(unit, state.name)]) %>%
  crossing(k = c(4, 9), group_type = c('canonical', 'sample', 'zone'))

hex_borders = hex_map %>%
  crossing(k = c(4, 9), group_type = c('canonical', 'sample', 'zone'))

nhsn_maup %>%
  filter(group_type == 'canonical' | iteration == 1, k %in% c(4, 9)) %>%
  mutate(unit = map(group, ~ nhsn_maup_data$`Ec/q`$unit_data$unit)) %>%
  select(k, group_type, group, unit) %>%
  unnest() %>%
  right_join(hex_borders, by = c('unit', 'k', 'group_type')) %>%
  ggplot(aes(x, y, group = unit)) +
  facet_grid(group_type ~ k) +
  geom_polygon(aes(fill = factor(group)), color = 'black', show.legend = FALSE) +
  geom_text(data = hex_labels, aes(label = abb)) +
  coord_fixed() +
  theme_void()
```

## Europe

```{r europe_data}
europe_maup_data = europe %>%
  nest(-bugdrug) %>%
  mutate(
    unit_data = map(data, ~ filter(europe_units, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

europe_canonical = crossing(
  bugdrug = europe$bugdrug,
  group_type = c('eu_country', 'eu_region')
)

europe_maup = maup_sim(
  bugdrug = unique(europe$bugdrug),
  k = c(4),
  n_iterations = 100,
  canonical_rows = europe_canonical,
  maup_data = europe_maup_data
)
```

### Canonical

```{r europe_canonical}
canonical_grouping_plot(europe_maup)
canonical_grouping_table(europe_maup)
```

### MAUP

```{r europe_maup_table}
maup_table(europe_maup, canonical_base = 'eu_country')
```

```{r europe_maup_plot}
maup_plot(europe_maup, canonical_base = 'eu_country')
```

## Canonical grouping analysis

### Significance test

To see if the observed (canonical) aggregate slope is anything special, compare it to the regional slopes you would get from permuting the region labels.

```{r aggregate_slope_analysis}
agg_slope_f = function(df, group, permute = FALSE) {
  expected_names = c(group, 'use', 'population', 'n_resistant', 'n_isolates')
  stopifnot(all(expected_names %in% names(df)))
  
  group_ = as.symbol(group)
  
  permute_f = if (permute) {
    function(x) mutate(x, !!group := sample(!!group_))
  } else {
    identity
  }
  
  dat = df %>%
    permute_f() %>%
    group_by(!!group_) %>%
    summarize(use = weighted.mean(use, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           res = n_resistant / n_isolates,
           lores = log(odds(res)))
  
  f = function(model) unname(coef(model)['use'])
  arru_slope = f(lm(res ~ use, data = dat))
  loru_slope = f(lm(lores ~ use, data = dat))
  
  c('arru' = arru_slope, 'loru' = loru_slope)
}

# group as character
agg_slope_p = function(df, group, n_iter) {
  obs_slope = agg_slope_f(df, group, permute = FALSE)
  perm_slopes = replicate(n_iter, agg_slope_f(df, group, permute = TRUE))
  
  r = rowSums(perm_slopes > obs_slope)
  (r + 1) / (n_iter + 1)
}

agg_slope = function(df, unit_data, groups, n_iter = 99) {
  dfn = quo_name(enquo(df))
  mutate(df) %>%
    left_join(unit_data, by = c('unit', 'population')) %>%
    nest(-bugdrug) %>%
    crossing(group = groups) %>%
    mutate(p_values = map2(data, group, ~ agg_slope_p(.x, .y, n_iter)),
           p_arru = map_dbl(p_values, ~ .['arru']),
           p_loru = map_dbl(p_values, ~ .['loru']),
           dataset = dfn) %>%
    select(-p_values)
}

agg_slope_results = bind_rows(
  agg_slope(marketscan, state_data, c('us_region', 'us_division')),
  agg_slope(nhsn, state_data, c('us_region', 'us_division')),
  agg_slope(europe, europe_units, c('eu_region'))
)

agg_slope_results %>%
  gather('metric', 'p_value', starts_with('p_')) %>%
  mutate(fdr = p.adjust(p_value, 'BH') < 0.05) %>%
  select(metric, bugdrug, group, p_value, fdr) %>%
  kable(caption = 'Empiricial tests, swapping the group labels')
```

## Distance analysis

If local tranmission "washes out" the use/resistance relationship, then we expect that pairs of states that are closer to one another will have a greater difference in resistance for the same difference in use. That is:
$$
\frac{\Delta \rho}{\Delta \tau} \sim d,
$$
where $d$ is the distance between the two units.

In these analyses, we'll zero-center $d$ by subtracting its mean so that the regression intercept gives the expected ARRU at "average" distances. This should be comparable to the slope in $\rho \sim \tau$ across units.

```{r dist_point}
odds_ratio = function(p, q) odds(p) / odds(q)
coef1 = function(model, term) model %>% coef() %>% extract(term) %>% unname()

# turn the bugdrug bundle into a pairwise list of dr, du, and distances
distance_fit_data = function(bd, permute = FALSE) {
  # prepare the data set
  d = bd$data %>%
    mutate(res = n_resistant / n_isolates,
           i = 1:n()) %>%
    select(unit, i, use, res)
  
  if (permute) {
    d %<>% mutate(i = sample(i))
  }
  
  # get all combinations of units
  units = unique(d$unit)
  crossing(unit1 = units, unit2 = units) %>%
    filter(unit1 < unit2) %>%
    left_join(d, by = c('unit1' = 'unit')) %>%
    left_join(d, by = c('unit2' = 'unit'), suffix = c('1', '2')) %>%
    mutate(dist = map2_dbl(i1, i2, ~ bd$unit_distances[.x, .y]),
           dr = res2 - res1,
           du = use2 - use1,
           arru = dr / du,
           loru = log(odds_ratio(res2, res1)) / du,
           d = dist - mean(dist))
}

bisquare = partial(MASS::rlm, psi = MASS::psi.bisquare)

regression_p = function(bd, n_iter = 99, method = bisquare) {
  vals = function(permute) {
    dfd = distance_fit_data(bd, permute = permute)
    
    arru = method(arru ~ d, data = dfd) %>%
      coef1('d')
    
    loru = method(loru ~ d, data = dfd) %>%
      coef1('d')
    
    c('arru' = arru, 'loru' = loru)
  }
  
  base_vals = vals(FALSE)
  perm_vals = replicate(n_iter, vals(TRUE))
  
  r = rowSums(perm_vals > base_vals)
  
  (r + 1) / (n_iter + 1)
}

# uses the t values reported by MASS::rlm
bs_model_p = function(model) {
  model %>%
    summary() %>%
    coef() %>%
    { .['d', 't value'] } %>%
    { -abs(.) } %>%
    pt(df = length(model$residuals) - 2)
}

confint.rlm = function(m) {
  cs = coef(summary(m))
  estimate = cs[, 'Value']
  se = cs[, 'Std. Error']
  result = cbind(estimate - 1.96 * se, estimate + 1.96 * se)
  rownames(result) <- names(estimate)
  colnames(result) <- c('2.5%', '97.5%')
  result
}

distance_fit = function(dataset, lst) {
  data_frame(
    dataset = dataset,
    bugdrug = names(lst),
    data = map(lst, distance_fit_data),
    model_arru = map(data, ~ bisquare(arru ~ d, data = .)),
    model_loru = map(data, ~ bisquare(loru ~ d, data = .)),
    p_values = map(lst, regression_p),
    arru_p = map_dbl(p_values, ~ .['arru']),
    loru_p = map_dbl(p_values, ~ .['loru'])
  )
}

distance_fit_results = bind_rows(
  distance_fit('marketscan', marketscan_maup_data),
  distance_fit('nhsn', nhsn_maup_data),
  distance_fit('europe', europe_maup_data)
)

distance_fit_table = function(model, p) {
  model_ = enquo(model)
  p_ = enquo(p)

  distance_fit_results %>%
    select(dataset, bugdrug, model = !!model_) %>%
    mutate(vals = map(model, tidy)) %>%
    select(-model) %>%
    unnest() %>%
    mutate_at(c('estimate', 'std.error'), function(x) if_else(.$term == 'd', 1e3 * x, x)) %>%
    mutate(hci = 1.96 * std.error,
           cil = estimate - hci,
           ciu = estimate + hci,
           range = sprintf('%.3f (%.3f to %.3f)', estimate, cil, ciu)) %>%
    select(dataset, bugdrug, term, range) %>%
    spread(term, range) %>%
    rename(slope = d) %>%
    left_join(select(distance_fit_results, dataset, bugdrug, slope_p = !!p_)) %>%
    mutate(fdr = p.adjust(slope_p, 'BH') < 0.05) %>%
    arrange(dataset, bugdrug)
}

distance_fit_table(model_arru, arru_p) %>%
  kable(caption = 'Point estimates of intercept (ARRU, in p.p. resistance per unit use) and slope (ARRU per 10^3 km).')

distance_fit_table(model_loru, loru_p) %>%
  kable(caption = 'Point estimates of intercept (LORU, in per unit use) and slope (LORU per 10^3 km).')
```
