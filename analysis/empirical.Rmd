---
title: "Empirical use-resistance relationships over geographic scales"
author: "Scott Olesen"
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  fig.width = 7, fig.height = 4, fig.path = 'fig/',
  dev = c('png', 'pdf'), 
  echo = FALSE, warning = FALSE, message = FALSE,
  cache = TRUE, autodep = TRUE)

pdf.options(useDingbats = FALSE, useKerning = FALSE)

map = purrr::map
select = dplyr::select
```

# Methods

## Data

### MarketScan

```{r maup_db}
state_data = read_tsv('../db/state_data.tsv') %>%
  rename(us_region = region, us_division = division) %>%
  mutate(density = population / area)
```

```{r marketscan_data}
marketscan_res = read_tsv('~/grad/proj/medicare/analysis/ms2/data/abg_state.tsv') %>%
  rename(drug = drug_group) %>%
  mutate(bugdrug = case_when(
    .$bug == 'E. coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'S. pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'S. pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  filter(!is.na(bugdrug)) %>%
  mutate(n_resistant = as.integer(round(f_ns * n_isolates))) %>%
  select(bugdrug, drug, state, n_resistant, n_isolates)

marketscan_use = read_tsv('~/grad/proj/medicare/analysis/ms2/ineq_marketscan.tsv') %>%
  rename(drug = drug_group, use = total_use) %>%
  filter(drug %in% c('quinolone', 'beta_lactam', 'macrolide'))

marketscan = marketscan_use %>%
  inner_join(marketscan_res, by = c('drug', 'state')) %>%
  rename(unit = state) %>%
  left_join(state_data, by = 'unit') %>%
  select(unit_id, unit, bugdrug, use, n_resistant, n_isolates, population, density, income, temperature)
```

### NHSN/IMS

```{r nhsn_ims}
nhsn = read_tsv('../data/nhsn-ims/data.tsv') %>%
  rename(state_abbreviation = state) %>%
  filter(state_abbreviation %in% state.abb) %>%
  mutate(unit_id = match(state_abbreviation, state.abb),
         bugdrug = 'Ec/q',
         use = rx_1k_year / 1e3) %>%
  arrange(unit_id) %>%
  left_join(state_data, by = 'unit_id') %>%
  select(unit_id, unit, bugdrug, use, n_resistant, n_isolates, population, density, income, temperature)
```

### ECDC

For the European data, we convert to "treatments" per person per year, assuming a certain conversion from DDD to treatments. This is just an *ad hoc* adjustment to get the European data to the same scales as used in the simulations and the US data.

```{r ecdc_convert}
did_cpy_map = data_frame(
  drug = c('beta_lactam', 'quinolone', 'macrolide'),
  ddd_per_tx = c(10, 10, 7),
  cpy_per_did = 365 / (1e3 * ddd_per_tx)
)

did_cpy_map %>%
  kable(caption = 'DDD to treatment conversion')
```

```{r ecdc}
europe_units = read_tsv('../db/europe_units.tsv') %>%
  mutate(density = population / area) %>%
  select(unit_id, unit, long = longitude, lat = latitude, population, eu_region = region, density, income, temperature)

europe = read_tsv('../data/ecdc/data.tsv') %>%
  left_join(did_cpy_map, by = 'drug') %>%
  mutate(use = cpy_per_did * did) %>%
  mutate(bugdrug = case_when(
    .$bug == 'Escherichia coli' & .$drug == 'quinolone' ~ 'Ec/q',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'beta_lactam' ~ 'Sp/bl',
    .$bug == 'Streptococcus pneumoniae' & .$drug == 'macrolide' ~ 'Sp/m'
  )) %>%
  rename(unit = country) %>%
  left_join(europe_units, by = 'unit') %>%
  select(unit_id, unit, bugdrug, use, n_resistant = n_ns, n_isolates, population, density, temperature, income)

europe_names = unique(europe$unit)
```

# Results

## MarketScan

```{r marketscan_maup_setup}
# group n items into k groups, with at least n_min items in each group
sample_nmin = function(n, k, n_min = 2) {
  stopifnot(n_min * k <= n)
  sample(c(rep(1:k, each = n_min), sample(1:k, n - (n_min * k), replace = TRUE)))
}

renumber = function(x) match(x, unique(x))

# given distances between things, create groups
random_zones = function(distances, k) {
  stopifnot(nrow(distances) == ncol(distances))
  stopifnot(nrow(distances) >= k)
  
  centers = sample(1:nrow(distances), k)
  zones = distances[, centers] %>%
    apply(1, function(x) centers[which.min(x)])
  
  renumber(zones)
}

# wrapper around random zones, to ensure group size
random_zones_nmin = function(distances, k, n_min = 2, max_tries = 1e2) {
  try = 1
  while (try < max_tries) {
    z = random_zones(distances, k)
    if (min(table(z)) >= n_min) return(z)
    try = try + 1
  }
  
  NULL
}

deg2rad = function(deg) deg * pi / 180

haversine = function(long1, lat1, long2, lat2, R = 6371) {
  long1 = deg2rad(long1)
  lat1 = deg2rad(lat1)
  long2 = deg2rad(long2)
  lat2 = deg2rad(lat2)
  R * acos(pmin(1.0, sin(lat1) * sin(lat2) + cos(lat1) * cos(lat2) * cos(long2 - long1)))
}

unit_distances = function(unit_data) {
  stopifnot(all(c('unit', 'long', 'lat') %in% names(unit_data)))
  if (any(duplicated(unit_data$unit))) stop('duplicated units')

  units = unit_data$unit
  n_units = length(units)
  
  unit_data %>%
    crossing(., .) %>%
    arrange(unit, unit1) %>%
    mutate(dist = haversine(long, lat, long1, lat1)) %$%
    matrix(dist, ncol = n_units, nrow = n_units) %>%
    set_rownames(units) %>%
    set_colnames(units)
}
```

```{r maup_helper_functions}
odds = function(p) p / (1 - p)

aggregate = function(df, group) {
  mutate(df, group = group) %>%
    group_by(group) %>%
    summarize(use = weighted.mean(use, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           res = n_resistant / n_isolates,
           lores = log(odds(res)))
}

try_load = function(fn, expr, force_run = FALSE) {
  if (!force_run && file.exists(fn)) {
    read_rds(fn)
  } else {
    value = expr
    write_rds(value, fn)
  }
}
```

```{r marketscan_maup_compute}
# create a hierarchical list: marketscan_maup_data$`Ec/q`$data
marketscan_maup_data = marketscan %>%
  nest(-bugdrug) %>%
  mutate(
    #state_id = map(data, ~ match(.$unit, state.name)),
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

# swo: could put the region, etc. data right in to the maup data, so that it's not floating around
# in multiple places

maup_group = function(maup_data, k, group_type) {
  switch(group_type,
         'sample' = sample_nmin(maup_data$n_units, k),
         'zone' = random_zones_nmin(maup_data$unit_distances, k),
         'us_state' = maup_data$data$unit_id,
         'us_division' = renumber(state.division[maup_data$data$unit_id]),
         'us_region' = renumber(state.region[maup_data$data$unit_id]),
         'eu_country' = maup_data$data$unit_id,
         'eu_region' = renumber(europe_units$eu_region[maup_data[[.y]]$state_id])
  )
}

marketscan_canonical = crossing(
  bugdrug = marketscan$bugdrug,
  group_type = c('us_state', 'us_division', 'us_region')
)

# swo: this code down here seems really redundant with what's above

add_canonical_data = function(df, maup_data) {
  df %>%
    mutate(group = map2(group_type, bugdrug,
                        ~ switch(.x,
                                 'us_state' = maup_data[[.y]]$data$unit_id,
                                 'us_division' = renumber(state.division[maup_data[[.y]]$data$unit_id]),
                                 'us_region' = renumber(state.region[maup_data[[.y]]$data$unit_id]),
                                 'eu_country' = maup_data[[.y]]$data$unit_id,
                                 'eu_region' = renumber(europe_units$eu_region[maup_data[[.y]]$data$unit_id])
                                 )),
           k = map_int(group, ~ length(unique(.))))
}

canonical_types = c('us_state', 'us_region', 'us_division', 'eu_country', 'eu_region')

maup_sim = function(bugdrug, k, n_iterations, canonical_rows, maup_data) {
  crossing(
    bugdrug = bugdrug,
    k = k,
    group_type = c('sample', 'zone'),
    iteration = 1:n_iterations
  ) %>%
    mutate(group = pmap(list(bugdrug, k, group_type), ~ maup_group(maup_data[[..1]], ..2, ..3))) %>%
    bind_rows(add_canonical_data(canonical_rows, maup_data)) %>%
    mutate(
      group_data = map2(bugdrug, group, ~ aggregate(maup_data[[.x]]$data, .y)),
      canonical_type = if_else(group_type %in% canonical_types, group_type, NA_character_),
      group_type = if_else(group_type %in% canonical_types, 'canonical', group_type),
      model_arru = map(group_data, ~ lm(res ~ use, data = .)),
      model_loru = map(group_data, ~ lm(lores ~ use, data = .)),
      slope_arru = map_dbl(model_arru, ~ coef(.)['use']),
      slope_loru = map_dbl(model_loru, ~ coef(.)['use']) 
    )
}

marketscan_maup = maup_sim(
  bugdrug = marketscan$bugdrug,
  k = c(4, 9),
  n_iterations = 100,
  canonical_rows = marketscan_canonical,
  maup_data = marketscan_maup_data
)
```

### MAUP

Histogram of slopes over the random aggregates (zonal and sample) for each bug/drug and $k$. Dotted blue line shows the slope over the raw units (states).

```{r marketscan_maup_plot}
maup_plot = function(maup, canonical_base = 'us_state', metric = 'slope_arru') {
  metric_ = as.symbol(metric)
  
  dat = maup %>%
    filter(group_type != 'canonical') %>%
    select(bugdrug, k, group_type, !!metric_)
  
  slopes = maup %>%
    filter(canonical_type == canonical_base) %>%
    select(bugdrug, base_slope = !!metric_) %>%
    crossing(k = unique(dat$k))
  
  dat %>%
    ggplot(aes(!!metric_, fill = group_type)) +
    facet_grid(k ~ bugdrug, scales = 'free') +
    geom_vline(
      data = slopes,
      aes(xintercept = base_slope),
      color = 'blue', linetype = 2
    ) +
    geom_histogram(position = 'dodge') +
    xlab(str_interp('slope (${metric}) over random aggregate'))
}

maup_plot(marketscan_maup)
```

## IMS/NHSN CAUTIs

```{r nhsn}
nhsn_maup_data = nhsn %>%
  nest(-bugdrug) %>%
  mutate(
    unit_data = map(data, ~ filter(state_data, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

nhsn_canonical = crossing(
  bugdrug = 'Ec/q',
  group_type = c('us_region', 'us_division', 'us_state')
)

nhsn_maup = maup_sim(
  bugdrug = 'Ec/q',
  k = c(4, 9),
  n_iterations = 100,
  canonical_rows = nhsn_canonical,
  maup_data = nhsn_maup_data
)
```

### MAUP

```{r nhsn_maup_plot}
maup_plot(nhsn_maup)
```

### Example regions

```{r hex}
hex_map = read_tsv('~/grad/db/us_hex.tsv') %>%
  filter(!is.na(state)) %>%
  rename(unit = state)

hex_labels = hex_map %>%
  filter(order %in% c(0, 3)) %>%
  group_by(unit) %>%
  summarize_at(c('x', 'y'), mean) %>%
  mutate(abb = state.abb[match(unit, state.name)]) %>%
  crossing(k = c(4, 9), group_type = c('canonical', 'sample', 'zone'))

hex_borders = hex_map %>%
  crossing(k = c(4, 9), group_type = c('canonical', 'sample', 'zone'))

hex_plot = nhsn_maup %>%
  filter(group_type == 'canonical' | iteration == 1, k %in% c(4, 9)) %>%
  mutate(unit = map(group, ~ nhsn_maup_data$`Ec/q`$unit_data$unit)) %>%
  select(k, group_type, group, unit) %>%
  unnest() %>%
  right_join(hex_borders, by = c('unit', 'k', 'group_type')) %>%
  ggplot(aes(x, y, group = unit)) +
  facet_grid(group_type ~ k) +
  geom_polygon(aes(fill = factor(group)), color = 'black', show.legend = FALSE) +
  geom_text(data = hex_labels, aes(label = abb), size = 1.5) +
  coord_fixed() +
  theme_void() +
  theme(
    text = element_text(size = 12)
  )

ggsave('fig/hex_plot.pdf', plot = hex_plot,
       width = 120, height = 100, units = 'mm')
```

## Europe

```{r europe_data}
europe_maup_data = europe %>%
  nest(-bugdrug) %>%
  mutate(
    unit_data = map(data, ~ filter(europe_units, unit %in% .$unit)),
    n_units = map_int(unit_data, nrow),
    unit_distances = map(unit_data, unit_distances)
  ) %>%
  gather('key', 'value', -bugdrug) %>%
  nest(key, value, .key = 'value_tbl') %>%
  mutate(value_list = map(value_tbl, ~ setNames(.$value, .$key))) %$%
  setNames(value_list, bugdrug)

europe_canonical = crossing(
  bugdrug = europe$bugdrug,
  group_type = c('eu_country', 'eu_region')
)

europe_maup = maup_sim(
  bugdrug = unique(europe$bugdrug),
  k = c(4),
  n_iterations = 100,
  canonical_rows = europe_canonical,
  maup_data = europe_maup_data
)
```

### MAUP

```{r europe_maup_plot}
maup_plot(europe_maup, canonical_base = 'eu_country')
```

## MAUP unified

```{r maup_slope_table}
maup = bind_rows(
  mutate(marketscan_maup, dataset = 'marketscan'),
  mutate(nhsn_maup, dataset = 'nhsn'),
  mutate(europe_maup, dataset = 'europe')
) %>%
  mutate(
    dataset = map_chr(dataset, ~ switch(., 'europe' = 'ECDC', 'nhsn' = 'IMS/NHSN', 'marketscan' = 'MarketScan')),
    level = factor(canonical_type, levels = c('us_state', 'us_division', 'us_region', 'eu_country', 'eu_region'))
  )

slopes = maup %>%
  select(dataset, bugdrug, k, group_type, canonical_type, starts_with('slope')) %>%
  gather('metric', 'slope', starts_with('slope'))

obs_slopes = slopes %>%
  filter(canonical_type %in% c('us_state', 'eu_country')) %>%
  select(dataset, bugdrug, metric, obs_slope = slope)

myf = function(x, digits) format(round(x, digits = digits), nsmall = digits)

pretty_p = function(x) {
  sig = case_when(
    p.adjust(x, 'BH') < 0.05 ~ '*',
    #x < 0.05 ~ '*',
    TRUE ~ ''
  )
  val = case_when(
    x < 0.01 ~ '<0.01',
    TRUE ~ myf(x, 2)
  )
  str_c(val, sig)
}

pretty_iqr = function(x, digits = 2) {
  quantile(x, c(0.25, 0.50, 0.75)) %>%
    myf(digits = digits) %>%
    { sprintf('%s (%s to %s)', .[1], .[2], .[3]) }
}

slopes %>%
  filter(group_type != 'canonical') %>%
  left_join(obs_slopes, by = c('dataset', 'bugdrug', 'metric')) %>%
  mutate(slope_diff = slope - obs_slope) %>%
  group_by(dataset, bugdrug, k, group_type, metric) %>%
  summarize(
    slope = list(slope),
    slope_diff = list(slope_diff),
    obs_slope = unique(obs_slope)
  ) %>%
  ungroup() %>%
  mutate(
    dbd = str_c(dataset, ', ', bugdrug),
    metric = str_replace(metric, '^slope_', ''),
    value = map_chr(slope, pretty_iqr),
    wilcox = map(slope_diff, ~ wilcox.test(., alternative = 'greater')),
    wilcox_p = map_dbl(wilcox, ~ .$p.value),
    p = pretty_p(wilcox_p),
    obs_slope = myf(obs_slope, 2)
  ) %>%
  select(group_type, dbd, dbd, metric, k, obs_slope, value, p) %>%
  arrange(rev(group_type), dbd, metric, k) %>%
  kable(caption = 'Comparing base and MAUP slopes')
```

## Canonical grouping analysis

### Unified report

```{r}
clean = function(x) as.character(round(x, 2))
peci = function(model) {
  pe = coef(model)['use']
  cil = confint(model)['use', 1]
  ciu = confint(model)['use', 2]
  sprintf('%s (%s to %s)', clean(pe), clean(cil), clean(ciu))
}

maup %>%
  filter(group_type == 'canonical') %>%
  mutate(
    arru = map_chr(model_arru, peci),
    loru = map_chr(model_loru, peci)
  ) %>%
  mutate(level = factor(
    canonical_type,
    levels = c('us_state', 'us_division', 'us_region', 'eu_country', 'eu_region')
  )) %>%
  arrange(dataset, bugdrug, level) %>%
  select(dataset, bugdrug, level, arru, loru) %>%
  kable(caption = 'Canonical grouping slopes')
```

### Unified figure

```{r canonical_marketscan}
marketscan_canonical_plot = maup %>%
  mutate(bugdrug = case_when(
    .$bugdrug == 'Ec/q' ~ 'E. coli & quinolones',
    .$bugdrug == 'Sp/bl' ~ 'S. pneumoniae & beta-lactams',
    .$bugdrug == 'Sp/m' ~ 'S. pneumoniae & macrolides'
  )) %>%
  filter(dataset == 'MarketScan') %>%
  filter(group_type == 'canonical') %>%
  select(bugdrug, level, data = group_data) %>%
  unnest() %>%
  ggplot(aes(use, res)) +
  facet_wrap(~ bugdrug, scales = 'free') +
  geom_smooth(aes(linetype = level), method = 'lm', alpha = 0.1, color = 'black', size = 0.5) +
  scale_linetype_manual(values = c(1, 3, 5, 1, 5)) +
  geom_point(aes(shape = level)) +
  scale_shape_manual(values = c(1, 2, 16, 1, 16)) +
  xlab('antibiotic use (yearly treatments per capita)') +
  ylab('antibiotic resistance (proportion of isolates)') +
  theme_classic() +
  theme(
    legend.position = 'none',
    strip.text = element_text(size = 8),
    axis.text = element_text(size = 8, color = 'black'),
    axis.title = element_text(size = 8)
  )

show(marketscan_canonical_plot)

ggsave('fig/marketscan_canonical.pdf', plot = marketscan_canonical_plot,
       width = 180, height = 80, units = 'mm')
```

```{r canonical_nhsn_ecdc}
other_canonical_plot = maup %>%
  filter(dataset != 'MarketScan') %>%
  filter(group_type == 'canonical') %>%
  mutate(dfd = str_c(dataset, ', ', bugdrug)) %>%
  select(dfd, level, data = group_data) %>%
  unnest() %>%
  ggplot(aes(use, res)) +
  facet_wrap(~ dfd, scales = 'free') +
  geom_smooth(aes(linetype = level), method = 'lm', alpha = 0.1, color = 'black', size = 0.5) +
  scale_linetype_manual(values = c(1, 3, 5, 1, 5)) +
  geom_point(aes(shape = level)) +
  scale_shape_manual(values = c(1, 2, 16, 1, 16)) +
  xlab('antibiotic use (yearly treatments per capita)') +
  ylab('antibiotic resistance (proportion of isolates)') +
  theme_classic() +
  theme(
    legend.position = 'none',
    strip.text = element_text(size = 8),
    axis.text = element_text(size = 8, color = 'black'),
    axis.title = element_text(size = 8)
  )

show(other_canonical_plot)

ggsave('fig/other_canonical.pdf', plot = other_canonical_plot,
       width = 180, height = 150, units = 'mm')
```

### Significance test

To see if the observed (canonical) aggregate slope is anything special, compare it to the regional slopes you would get from permuting the region labels.

```{r aggregate_slope_analysis}
agg_slope_f = function(df, group, permute = FALSE) {
  expected_names = c(group, 'use', 'population', 'n_resistant', 'n_isolates')
  stopifnot(all(expected_names %in% names(df)))
  
  group_ = as.symbol(group)
  
  permute_f = if (permute) {
    function(x) mutate(x, !!group := sample(!!group_))
  } else {
    identity
  }
  
  dat = df %>%
    permute_f() %>%
    group_by(!!group_) %>%
    summarize(use = weighted.mean(use, w = population),
              n_resistant = sum(n_resistant),
              n_isolates = sum(n_isolates)) %>%
    mutate(n_susceptible = n_isolates - n_resistant,
           res = n_resistant / n_isolates,
           lores = log(odds(res)))
  
  f = function(model) unname(coef(model)['use'])
  arru_slope = f(lm(res ~ use, data = dat))
  loru_slope = f(lm(lores ~ use, data = dat))
  
  c('arru' = arru_slope, 'loru' = loru_slope)
}

# group as character
agg_slope_p = function(df, group, n_iter) {
  obs_slope = agg_slope_f(df, group, permute = FALSE)
  perm_slopes = replicate(n_iter, agg_slope_f(df, group, permute = TRUE))
  
  r = rowSums(perm_slopes > obs_slope)
  (r + 1) / (n_iter + 1)
}

agg_slope = function(df, unit_data, groups, n_iter = 99) {
  dfn = quo_name(enquo(df))
  mutate(df) %>%
    left_join(unit_data, by = c('unit', 'population')) %>%
    nest(-bugdrug) %>%
    crossing(group = groups) %>%
    mutate(p_values = map2(data, group, ~ agg_slope_p(.x, .y, n_iter)),
           p_arru = map_dbl(p_values, ~ .['arru']),
           p_loru = map_dbl(p_values, ~ .['loru']),
           dataset = dfn) %>%
    select(-p_values)
}

agg_slope_results = bind_rows(
  agg_slope(marketscan, state_data, c('us_region', 'us_division')),
  agg_slope(nhsn, state_data, c('us_region', 'us_division')),
  agg_slope(europe, europe_units, c('eu_region'))
)

agg_slope_results %>%
  gather('metric', 'p_value', starts_with('p_')) %>%
  mutate(fdr = p.adjust(p_value, 'BH') < 0.05) %>%
  select(metric, bugdrug, group, p_value, fdr) %>%
  kable(caption = 'Empiricial tests, swapping the group labels')
```

## Distance analysis

If local tranmission "washes out" the use/resistance relationship, then we expect that pairs of states that are closer to one another will have a greater difference in resistance for the same difference in use. That is:
$$
\frac{\Delta \rho}{\Delta \tau} \sim d,
$$
where $d$ is the distance between the two units.

In these analyses, we'll zero-center $d$ by subtracting its mean so that the regression intercept gives the expected ARRU at "average" distances. This should be comparable to the slope in $\rho \sim \tau$ across units.

```{r dist_point}
odds_ratio = function(p, q) odds(p) / odds(q)
coef1 = function(model, term) model %>% coef() %>% extract(term) %>% unname()
coef2 = function(x) coef1(x, 'du:d') / coef1(x, 'du')

# turn the bugdrug bundle into a pairwise list of dr, du, and distances
distance_fit_data = function(bd, permute = FALSE) {
  # prepare the data set
  df = bd$data %>%
    mutate(res = n_resistant / n_isolates,
           i = 1:n()) %>%
    select(unit, i, use, res, density, income, temperature)
  
  if (permute) {
    df %<>% mutate(i = sample(i))
  }
  
  # get all combinations of units
  units = unique(df$unit)
  crossing(unit1 = units, unit2 = units) %>%
    filter(unit1 < unit2) %>%
    left_join(df, by = c('unit1' = 'unit')) %>%
    left_join(df, by = c('unit2' = 'unit'), suffix = c('1', '2')) %>%
    mutate(
      # use the (possibly shuffled) distances
      d = map2_dbl(i1, i2, ~ bd$unit_distances[.x, .y]),
      dr = res2 - res1,
      du = use2 - use1,
      lor = log(odds(res2)) - log(odds(res1)),
      # other determinants
      d_density = density2 - density1,
      d_income = income2 - income1,
      d_temp = temperature2 - temperature1
    )
}

bisquare = partial(MASS::rlm, psi = MASS::psi.bisquare)

regression_p = function(bd, n_iter = 999, method = bisquare) {
  vals = function(permute) {
    dfd = distance_fit_data(bd, permute = permute)
    
    arru = method(dr ~ du + du:d + d_density + d_income + d_temp, data = dfd) %>% coef2()
    loru = method(lor ~ du + du:d + d_density + d_income + d_temp, data = dfd) %>% coef2()
    # unadjusted models
    arru_ua = method(dr ~ du + du:d, data = dfd) %>% coef2()
    loru_ua = method(lor ~ du + du:d, data = dfd) %>% coef2()
    
    c('arru' = arru, 'loru' = loru,
      'arru_ua' = arru_ua, 'loru_ua' = loru_ua)
  }
  
  base_vals = vals(FALSE)
  perm_vals = replicate(n_iter, vals(TRUE))
  
  r = rowSums(perm_vals > base_vals)
  
  (r + 1) / (n_iter + 1)
}

# uses the t values reported by MASS::rlm
model_p = function(model) {
  df = length(model$residuals) - length(coef(model))
  t_vals = coef(summary(model))[, 't value']
  2 * pt(-abs(t_vals), df = df)
}

confint.rlm = function(m) {
  cs = coef(summary(m))
  estimate = cs[, 'Value']
  se = cs[, 'Std. Error']
  
  cbind(estimate - 1.96 * se, estimate + 1.96 * se) %>%
    set_rownames(names(estimate)) %>%
    set_colnames(c('2.5%', '97.5%'))
}

distance_fit = function(dataset, lst) {
  data_frame(
    dataset = dataset,
    bugdrug = names(lst),
    data = map(lst, distance_fit_data),
    # adjusted models
    model_arru = map(data, ~ bisquare(dr ~ du + du:d + d_density + d_income + d_temp, data = .)),
    model_loru = map(data, ~ bisquare(lor ~ du + du:d + d_density + d_income + d_temp, data = .)),
    # unadjusted models
    model_arru_ua = map(data, ~ bisquare(dr ~ du + du:d, data = .)),
    model_loru_ua = map(data, ~ bisquare(lor ~ du + du:d, data = .)),
    # p values
    p_values = map(lst, regression_p),
    arru_p = map_dbl(p_values, ~ .['arru']),
    loru_p = map_dbl(p_values, ~ .['loru']),
    arru_p_ua = map_dbl(p_values, ~ .['arru_ua']),
    loru_p_ua = map_dbl(p_values, ~ .['loru_ua'])
  )
}

distance_fit_results = bind_rows(
  distance_fit('marketscan', marketscan_maup_data),
  distance_fit('nhsn', nhsn_maup_data),
  distance_fit('europe', europe_maup_data)
)
```

```{r}
peci = function(model, term, digits = 2, mult = 1) {
  pe = coef1(model, term)
  ci = confint(model)[term, ]
  clean = function(x) as.character(round(x, digits))
  sprintf('%s (%s to %s)', clean(pe * mult), clean(ci[1] * mult), clean(ci[2] * mult))
}

distance_fit_results %>%
  mutate(
    arru_du = map_chr(model_arru, ~ peci(., 'du')),
    arru_dud = map_chr(model_arru, ~ peci(., 'du:d', mult = 1e3)),
    arru_ratio = map_dbl(model_arru, ~ round(coef2(.) * 1e3, 2)),
    loru_du = map_chr(model_loru, ~ peci(., 'du')),
    loru_dud = map_chr(model_loru, ~ peci(., 'du:d', mult = 1e3)),
    loru_ratio = map_dbl(model_loru, ~ round(coef2(.) * 1e3, 2))
  ) %>%
  select(
    dataset, bugdrug,
    arru_du, arru_dud, arru_ratio, arru_p,
    loru_du, loru_dud, loru_ratio, loru_p
  ) %>%
  kable()
```

### Plots

```{r dist_point_plot}
library(MASS)
ycut = 75

dat = distance_fit_results %>%
  filter(dataset == 'europe', bugdrug == 'Ec/q') %$%
  data[[1]] %>%
  mutate(loru = lor / du)

dpp = dat %>%
  ggplot(aes(d, loru)) +
  geom_point(shape = 1) +
  geom_smooth(method = 'rlm', color = 'black', size = 0.5) +
  coord_cartesian(ylim = ycut * c(-1, 1)) +
  xlab('Distance between countries (km)') +
  ylab('use-resistance relationship (LORU)') +
  theme_classic() +
  theme(
    axis.text = element_text(size = 8, color = 'black'),
    axis.title = element_text(size = 8)
  )

dpp

dat %>%
  count(abs(loru) <= ycut) %>%
  kable(caption = 'Counts of points inside the y-axis truncated')

ggsave('fig/distance_plot.pdf', plot = dpp, width = 88, units = 'mm')
ggsave('fig/distance_plot.png', plot = dpp, width = 88, units = 'mm')
```

```{r dist_point_all}
is_central = function(x, q) {
  stopifnot(between(q, 0, 1))
  threshold = ecdf(abs(x)) %>% quantile(q)
  abs(x) < threshold
}

dist_point_dat = distance_fit_results %>%
  mutate(
    dataset = map_chr(dataset, ~ switch(., 'europe' = 'ECDC', 'nhsn' = 'IMS/NHSN', 'marketscan' = 'MarketScan')),
    dfd = str_c(dataset, ', ', bugdrug),
    data = map(data, ~ filter(mutate(., loru = lor / du), is.finite(loru))),
    model = map(data, ~ bisquare(loru ~ d, data = .)),
    intercept = map_dbl(model, ~ coef(.)['(Intercept)']),
    slope = map_dbl(model, ~ coef(.)['d'])
  )

dist_point_dat %>%
  select(dfd, data) %>%
  unnest() %>%
  # truncate axes
  group_by(dfd) %>%
  filter(is_central(loru, 0.95)) %>%
  ungroup() %>%
  ggplot(aes(d, loru)) +
  facet_wrap(~ dfd, scales = 'free') +
  geom_point(shape = 1) +
  geom_hline(yintercept = 0, color = 'blue') +
  geom_abline(data = dist_point_dat, aes(intercept = intercept, slope = slope), color = 'red') +
  xlab('Distance between units (km)') +
  ylab('use-resistance relationship (LORU)') +
  theme_classic()
```

# Discussion

```{r concept}
exp_f = function(x0, b) {
  function(x) 1 - exp(-(x - x0) / b)
}

logistic_f = function(x0, b) {
  function(x) 1 / (1 + exp(-(x - x0) / b))
}

line1 = exp_f(-1, 0.2)
line2 = logistic_f(-0.2, 0.2)
line3 = logistic_f(0.5, 0.2)

known = data_frame(
  x = c(-1, 1, 1.5),
  y = c(0, 1, 1),
  level = c('individual', 'state', 'region')
)

guess = data_frame(
  x = c(-0.5, 0.5),
  y = c(line1(-0.5), line2(0.5)),
  level = c('daycare', 'city')
)

concept_plot = ggplot(known, aes(x, y)) +
  geom_point(shape = 16, size = 3) +
  geom_point(data = guess, shape = 1, size = 3) +
  geom_segment(data = guess, aes(xend = x, yend = -0.1), linetype = 3) +
  stat_function(fun = line1, linetype = 2) +
  stat_function(fun = line2, linetype = 2) +
  stat_function(fun = line3, linetype = 2) +
  scale_y_continuous(
    'effect size',
    limits = c(-0.1, 1.1), expand = c(0, 0),
    breaks = c(0, 1), labels = c('', '')
  ) +
  scale_x_continuous(
    'intervention scale',
    limits = c(-1.0, 1.6), expand = c(0, 0),
    breaks = c(-1, -0.5, 0.5, 1.0, 1.5),
    labels = c('individual', 'daycare', 'city', 'state', 'region')
  ) +
  theme_classic() +
  theme(
    axis.text = element_text(color = 'black', size = 10),
    axis.title = element_text(size = 12)
  )

show(concept_plot)

ggsave('fig/concept.pdf', plot = concept_plot,
       width = 88, units = 'mm')
```
